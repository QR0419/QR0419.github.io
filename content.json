{"meta":{"title":"个人博客","subtitle":"","description":"","author":"QR","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"Hello World","date":"2024-06-04T02:18:07.576Z","path":"2024/06/04/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","slug":"hello-world","updated":"2024-06-04T02:18:07.576Z","comments":true,"permalink":"http://example.com/2024/06/04/hello-world/","tags":[]},{"title":"《Spark HA & Yarn 配置》","date":"2024-06-03T05:37:58.000Z","path":"2024/06/03/Spark3/","text":"Spark StandAlone HA 环境搭建步骤 前提: 确保Zookeeper 和 HDFS 均已经启动 先在spark-env.sh中, 删除: SPARK_MASTER_HOST=node1 原因: 配置文件中固定master是谁, 那么就无法用到zk的动态切换master功能了. 在spark-env.sh中, 增加: 1234SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node1:2181,node2:2181,node3:2181 -Dspark.deploy.zookeeper.dir=/spark-ha&quot;# spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现# 指定Zookeeper的连接地址# 指定在Zookeeper中注册临时节点的路径 将spark-env.sh 分发到每一台服务器上 12scp spark-env.sh node2:/export/server/spark/conf/scp spark-env.sh node3:/export/server/spark/conf/ 停止当前StandAlone集群 1sbin/stop-all.sh 启动集群: 123456# 在node1上 启动一个master 和全部workersbin/start-all.sh# 注意, 下面命令在node2上执行sbin/start-master.sh# 在node2上启动一个备用的master进程 master主备切换提交一个spark任务到当前alivemaster上: 1bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 1000 在提交成功后, 将alivemaster直接kill掉 不会影响程序运行:当新的master接收集群后, 程序继续运行, 正常得到结果. 结论 HA模式下, 主备切换 不会影响到正在运行的程序. 最大的影响是 会让它中断大约30秒左右. Spark On YARN 环境搭建部署确保: HADOOP_CONF_DIR YARN_CONF_DIR 在spark-env.sh 以及 环境变量配置文件中即可​ 连接到YARN中bin&#x2F;pyspark12345bin/pyspark --master yarn --deploy-mode client|cluster# --deploy-mode 选项是指定部署模式, 默认是 客户端模式# client就是客户端模式# cluster就是集群模式# --deploy-mode 仅可以用在YARN模式下 注意: 交互式环境 pyspark 和 spark-shell 无法运行 cluster模式 bin&#x2F;spark-shell1bin/spark-shell --master yarn --deploy-mode client|cluster 注意: 交互式环境 pyspark 和 spark-shell 无法运行 cluster模式 bin&#x2F;spark-submit (PI)1bin/spark-submit --master yarn --deploy-mode client|cluster /xxx/xxx/xxx.py 参数 spark-submit 和 spark-shell 和 pyspark的相关参数参见: 附2​ 附1 Anaconda On Linux 安装 (单台服务器)安装上传安装包: 上传: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上 安装: sh ./Anaconda3-2021.05-Linux-x86_64.sh输入yes后就安装完成了. 安装完成后, 退出finalshell 重新进来: 看到这个Base开头表明安装好了. base是默认的虚拟环境.​ 国内源如果你安装好后, 没有出现base, 可以打开:&#x2F;root&#x2F;.condarc这个文件, 追加如下内容: 1234567891011121314channels: - defaultsshow_channel_urls: truedefault_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud 附2 spark-submit和pyspark相关参数客户端工具我们可以用的有: bin&#x2F;pyspark: pyspark解释器spark环境 bin&#x2F;spark-shell: scala解释器spark环境 bin&#x2F;spark-submit: 提交jar包或Python文件执行的工具 bin&#x2F;spark-sql: sparksql客户端工具 这4个客户端工具的参数基本通用. 以spark-submit 为例: bin/spark-submit --master spark://node1:7077 xxx.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374Usage: spark-submit [options] &lt;app jar | python file | R file&gt; [app arguments]Usage: spark-submit --kill [submission ID] --master [spark://...]Usage: spark-submit --status [submission ID] --master [spark://...]Usage: spark-submit run-example [options] example-class [example args]Options: --master MASTER_URL spark://host:port, mesos://host:port, yarn, k8s://https://host:port, or local (Default: local[*]). --deploy-mode DEPLOY_MODE 部署模式 client 或者 cluster 默认是client --class CLASS_NAME 运行java或者scala class(for Java / Scala apps). --name NAME 程序的名字 --jars JARS Comma-separated list of jars to include on the driver and executor classpaths. --packages Comma-separated list of maven coordinates of jars to include on the driver and executor classpaths. Will search the local maven repo, then maven central and any additional remote repositories given by --repositories. The format for the coordinates should be groupId:artifactId:version. --exclude-packages Comma-separated list of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts. --repositories Comma-separated list of additional remote repositories to search for the maven coordinates given with --packages. --py-files PY_FILES 指定Python程序依赖的其它python文件 --files FILES Comma-separated list of files to be placed in the working directory of each executor. File paths of these files in executors can be accessed via SparkFiles.get(fileName). --archives ARCHIVES Comma-separated list of archives to be extracted into the working directory of each executor. --conf, -c PROP=VALUE 手动指定配置 --properties-file FILE Path to a file from which to load extra properties. If not specified, this will look for conf/spark-defaults.conf. --driver-memory MEM Driver的可用内存(Default: 1024M). --driver-java-options Driver的一些Java选项 --driver-library-path Extra library path entries to pass to the driver. --driver-class-path Extra class path entries to pass to the driver. Note that jars added with --jars are automatically included in the classpath. --executor-memory MEM Executor的内存 (Default: 1G). --proxy-user NAME User to impersonate when submitting the application. This argument does not work with --principal / --keytab. --help, -h 显示帮助文件 --verbose, -v Print additional debug output. --version, 打印版本 Cluster deploy mode only(集群模式专属): --driver-cores NUM Driver可用的的CPU核数(Default: 1). Spark standalone or Mesos with cluster deploy mode only: --supervise 如果给定, 可以尝试重启Driver Spark standalone, Mesos or K8s with cluster deploy mode only: --kill SUBMISSION_ID 指定程序ID kill --status SUBMISSION_ID 指定程序ID 查看运行状态 Spark standalone, Mesos and Kubernetes only: --total-executor-cores NUM 整个任务可以给Executor多少个CPU核心用 Spark standalone, YARN and Kubernetes only: --executor-cores NUM 单个Executor能使用多少CPU核心 Spark on YARN and Kubernetes only(YARN模式下): --num-executors NUM Executor应该开启几个 --principal PRINCIPAL Principal to be used to login to KDC. --keytab KEYTAB The full path to the file that contains the keytab for the principal specified above. Spark on YARN only: --queue QUEUE_NAME 指定运行的YARN队列(Default: &quot;default&quot;). 附3 Windows系统配置Anaconda安装打开资料中提供的:Anaconda3-2021.05-Windows-x86_64.exe文件,或者去官网下载:[https://www.anaconda.com/products/individual#Downloads]​ 打开后,一直点击Next下一步即可:如果想要修改安装路径, 可以修改不必勾选最终点击Finish完成安装 打开开始菜单, 搜索Anaconda出现如图的程序, 安装成功. 打开 Anaconda Prompt程序:出现base说明安装正确. 配置国内源Anaconda默认源服务器在国外, 网速比较慢, 配置国内源加速网络下载.​ 打开上图中的 Anaconda Prompt程序:执行:conda config --set show_channel_urls yes​ 然后用记事本打开:C:\\Users\\用户名\\.condarc文件, 将如下内容替换进文件内,保存即可: 1234567891011121314channels: - defaultsshow_channel_urls: truedefault_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud 创建虚拟环境1234567891011# 创建虚拟环境 pyspark, 基于Python 3.8conda activate base conda create -n pyspark python=3.8# 切换到虚拟环境内conda activate pyspark# 在虚拟环境内安装包pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple pip install pyspark==3.2.0 -i https://pypi.tuna.tsinghua.edu.cn/simple","raw":"---\ntitle: 《Spark HA & Yarn 配置》\ndate: 2024-06-03 13:37:58\ntags: Spark(HA)，Spark(Yarn)\n---\n\n# Spark StandAlone HA 环境搭建\n\n\n## 步骤\n\n> 前提: 确保Zookeeper 和 HDFS 均已经启动\n\n\n\n先在`spark-env.sh`中, 删除: `SPARK_MASTER_HOST=node1`\n\n\n原因: 配置文件中固定master是谁, 那么就无法用到zk的动态切换master功能了.\n\n\n在`spark-env.sh`中, 增加:\n\n\n```shell\nSPARK_DAEMON_JAVA_OPTS=\"-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node1:2181,node2:2181,node3:2181 -Dspark.deploy.zookeeper.dir=/spark-ha\"\n# spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现\n# 指定Zookeeper的连接地址\n# 指定在Zookeeper中注册临时节点的路径\n```\n\n\n将spark-env.sh 分发到每一台服务器上\n\n\n```shell\nscp spark-env.sh node2:/export/server/spark/conf/\nscp spark-env.sh node3:/export/server/spark/conf/\n```\n\n\n停止当前StandAlone集群\n\n\n```shell\nsbin/stop-all.sh\n```\n\n\n启动集群:\n\n\n```shell\n# 在node1上 启动一个master 和全部worker\nsbin/start-all.sh\n\n# 注意, 下面命令在node2上执行\nsbin/start-master.sh\n# 在node2上启动一个备用的master进程\n```\n\n![](/2024/06/03/Spark3/14.jpg)\n![](/2024/06/03/Spark3/15.jpg)\n\n## master主备切换\n\n\n提交一个spark任务到当前`alive`master上:\n\n\n```shell\nbin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 1000\n```\n\n\n在提交成功后, 将alivemaster直接kill掉\n\n不会影响程序运行:\n![](/2024/06/03/Spark3/16.jpg)\n当新的master接收集群后, 程序继续运行, 正常得到结果.\n\n\n> 结论 HA模式下, 主备切换 不会影响到正在运行的程序.\n>\n> 最大的影响是 会让它中断大约30秒左右.\n\n\n\n\n\n# Spark On YARN 环境搭建\n\n## 部署\n\n确保:\n\n\n- HADOOP_CONF_DIR\n- YARN_CONF_DIR\n\n\n\n在spark-env.sh 以及 环境变量配置文件中即可\n​\n\n## 连接到YARN中\n\n\n### bin/pyspark\n\n\n```shell\nbin/pyspark --master yarn --deploy-mode client|cluster\n# --deploy-mode 选项是指定部署模式, 默认是 客户端模式\n# client就是客户端模式\n# cluster就是集群模式\n# --deploy-mode 仅可以用在YARN模式下\n```\n\n\n> 注意: 交互式环境 pyspark  和 spark-shell  无法运行 cluster模式\n\n\n\n### bin/spark-shell\n\n\n```shell\nbin/spark-shell --master yarn --deploy-mode client|cluster\n```\n\n\n> 注意: 交互式环境 pyspark  和 spark-shell  无法运行 cluster模式\n\n\n\n### bin/spark-submit (PI)\n\n\n```shell\nbin/spark-submit --master yarn --deploy-mode client|cluster /xxx/xxx/xxx.py 参数\n```\n\n\n## spark-submit 和 spark-shell 和 pyspark的相关参数\n\n\n参见: 附2\n​\n\n\n\n# 附1 Anaconda On Linux 安装 (单台服务器)\n\n\n## 安装\n\n\n上传安装包:\n\n\n上传: 资料中提供的`Anaconda3-2021.05-Linux-x86_64.sh`文件到Linux服务器上\n\n\n安装:\n\n`sh ./Anaconda3-2021.05-Linux-x86_64.sh`\n![](/2024/06/03/Spark3/17.jpg)\n![](/2024/06/03/Spark3/18.jpg)\n![](/2024/06/03/Spark3/19.jpg)\n![](/2024/06/03/Spark3/20.jpg)\n![](/2024/06/03/Spark3/21.jpg)\n输入yes后就安装完成了.\n\n安装完成后, `退出finalshell 重新进来`:\n![](/2024/06/03/Spark3/22.jpg)\n\n\n看到这个Base开头表明安装好了.\n\n\nbase是默认的虚拟环境.\n​\n\n## 国内源\n\n如果你安装好后, 没有出现base, 可以打开:/root/.condarc这个文件, 追加如下内容:\n\n```shell\nchannels:\n  - defaults\nshow_channel_urls: true\ndefault_channels:\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2\ncustom_channels:\n  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n```\n\n\n# 附2 spark-submit和pyspark相关参数\n\n\n客户端工具我们可以用的有:\n\n\n- bin/pyspark: pyspark解释器spark环境\n- bin/spark-shell: scala解释器spark环境\n- bin/spark-submit: 提交jar包或Python文件执行的工具\n- bin/spark-sql: sparksql客户端工具\n\n\n\n这4个客户端工具的参数基本通用.\n\n\n以spark-submit 为例:\n\n\n`bin/spark-submit --master spark://node1:7077 xxx.py`\n\n\n```shell\nUsage: spark-submit [options] <app jar | python file | R file> [app arguments]\nUsage: spark-submit --kill [submission ID] --master [spark://...]\nUsage: spark-submit --status [submission ID] --master [spark://...]\nUsage: spark-submit run-example [options] example-class [example args]\n\nOptions:\n  --master MASTER_URL         spark://host:port, mesos://host:port, yarn,\n                              k8s://https://host:port, or local (Default: local[*]).\n  --deploy-mode DEPLOY_MODE   部署模式 client 或者 cluster 默认是client\n  --class CLASS_NAME          运行java或者scala class(for Java / Scala apps).\n  --name NAME                 程序的名字\n  --jars JARS                 Comma-separated list of jars to include on the driver\n                              and executor classpaths.\n  --packages                  Comma-separated list of maven coordinates of jars to include\n                              on the driver and executor classpaths. Will search the local\n                              maven repo, then maven central and any additional remote\n                              repositories given by --repositories. The format for the\n                              coordinates should be groupId:artifactId:version.\n  --exclude-packages          Comma-separated list of groupId:artifactId, to exclude while\n                              resolving the dependencies provided in --packages to avoid\n                              dependency conflicts.\n  --repositories              Comma-separated list of additional remote repositories to\n                              search for the maven coordinates given with --packages.\n  --py-files PY_FILES         指定Python程序依赖的其它python文件\n  --files FILES               Comma-separated list of files to be placed in the working\n                              directory of each executor. File paths of these files\n                              in executors can be accessed via SparkFiles.get(fileName).\n  --archives ARCHIVES         Comma-separated list of archives to be extracted into the\n                              working directory of each executor.\n\n  --conf, -c PROP=VALUE       手动指定配置\n  --properties-file FILE      Path to a file from which to load extra properties. If not\n                              specified, this will look for conf/spark-defaults.conf.\n\n  --driver-memory MEM         Driver的可用内存(Default: 1024M).\n  --driver-java-options       Driver的一些Java选项\n  --driver-library-path       Extra library path entries to pass to the driver.\n  --driver-class-path         Extra class path entries to pass to the driver. Note that\n                              jars added with --jars are automatically included in the\n                              classpath.\n\n  --executor-memory MEM       Executor的内存 (Default: 1G).\n\n  --proxy-user NAME           User to impersonate when submitting the application.\n                              This argument does not work with --principal / --keytab.\n\n  --help, -h                  显示帮助文件\n  --verbose, -v               Print additional debug output.\n  --version,                  打印版本\n\n Cluster deploy mode only(集群模式专属):\n  --driver-cores NUM          Driver可用的的CPU核数(Default: 1).\n\n Spark standalone or Mesos with cluster deploy mode only:\n  --supervise                 如果给定, 可以尝试重启Driver\n\n Spark standalone, Mesos or K8s with cluster deploy mode only:\n  --kill SUBMISSION_ID        指定程序ID kill\n  --status SUBMISSION_ID      指定程序ID 查看运行状态\n\n Spark standalone, Mesos and Kubernetes only:\n  --total-executor-cores NUM  整个任务可以给Executor多少个CPU核心用\n\n Spark standalone, YARN and Kubernetes only:\n  --executor-cores NUM        单个Executor能使用多少CPU核心\n\n Spark on YARN and Kubernetes only(YARN模式下):\n  --num-executors NUM         Executor应该开启几个\n  --principal PRINCIPAL       Principal to be used to login to KDC.\n  --keytab KEYTAB             The full path to the file that contains the keytab for the\n                              principal specified above.\n\n Spark on YARN only:\n  --queue QUEUE_NAME          指定运行的YARN队列(Default: \"default\").\n```\n\n\n\n\n# 附3 Windows系统配置Anaconda\n\n## 安装\n\n打开资料中提供的:Anaconda3-2021.05-Windows-x86_64.exe文件,或者去官网下载:[https://www.anaconda.com/products/individual#Downloads]\n​\n\n打开后,一直点击`Next`下一步即可:\n![image.png](/2024/06/03/Spark3/23.jpg)\n![image.png](/2024/06/03/Spark3/24.jpg)\n如果想要修改安装路径, 可以修改\n![image.png](/2024/06/03/Spark3/25.jpg)\n不必勾选\n![image.png](/2024/06/03/Spark3/26.jpg)\n最终点击Finish完成安装\n\n打开开始菜单, 搜索Anaconda\n![image.png](/2024/06/03/Spark3/27.jpg)\n出现如图的程序, 安装成功.\n\n打开 `Anaconda Prompt`程序:\n![image.png](/2024/06/03/Spark3/28.jpg)\n出现`base`说明安装正确.\n\n\n\n## 配置国内源\n\nAnaconda默认源服务器在国外, 网速比较慢, 配置国内源加速网络下载.\n​\n\n打开上图中的 `Anaconda Prompt`程序:\n执行:\n`conda config --set show_channel_urls yes`\n​\n\n然后用记事本打开:\n`C:\\Users\\用户名\\.condarc`文件, 将如下内容替换进文件内,保存即可:\n\n```shell\nchannels:\n  - defaults\nshow_channel_urls: true\ndefault_channels:\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2\ncustom_channels:\n  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n```\n\n\n## 创建虚拟环境\n\n\n```shell\n# 创建虚拟环境 pyspark, 基于Python 3.8\nconda activate base \nconda create -n pyspark python=3.8\n\n# 切换到虚拟环境内\nconda activate pyspark\n\n# 在虚拟环境内安装包\npip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple \n\npip install pyspark==3.2.0 -i https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n","content":"<h1 id=\"Spark-StandAlone-HA-环境搭建\"><a href=\"#Spark-StandAlone-HA-环境搭建\" class=\"headerlink\" title=\"Spark StandAlone HA 环境搭建\"></a>Spark StandAlone HA 环境搭建</h1><h2 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h2><blockquote>\n<p>前提: 确保Zookeeper 和 HDFS 均已经启动</p>\n</blockquote>\n<p>先在<code>spark-env.sh</code>中, 删除: <code>SPARK_MASTER_HOST=node1</code></p>\n<p>原因: 配置文件中固定master是谁, 那么就无法用到zk的动态切换master功能了.</p>\n<p>在<code>spark-env.sh</code>中, 增加:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node1:2181,node2:2181,node3:2181 -Dspark.deploy.zookeeper.dir=/spark-ha&quot;</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">指定Zookeeper的连接地址</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">指定在Zookeeper中注册临时节点的路径</span></span><br></pre></td></tr></table></figure>\n\n\n<p>将spark-env.sh 分发到每一台服务器上</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp spark-env.sh node2:/export/server/spark/conf/</span><br><span class=\"line\">scp spark-env.sh node3:/export/server/spark/conf/</span><br></pre></td></tr></table></figure>\n\n\n<p>停止当前StandAlone集群</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/stop-all.sh</span><br></pre></td></tr></table></figure>\n\n\n<p>启动集群:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">在node1上 启动一个master 和全部worker</span></span><br><span class=\"line\">sbin/start-all.sh</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">注意, 下面命令在node2上执行</span></span><br><span class=\"line\">sbin/start-master.sh</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">在node2上启动一个备用的master进程</span></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/06/03/Spark3/14.jpg\"><br><img src=\"/2024/06/03/Spark3/15.jpg\"></p>\n<h2 id=\"master主备切换\"><a href=\"#master主备切换\" class=\"headerlink\" title=\"master主备切换\"></a>master主备切换</h2><p>提交一个spark任务到当前<code>alive</code>master上:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 1000</span><br></pre></td></tr></table></figure>\n\n\n<p>在提交成功后, 将alivemaster直接kill掉</p>\n<p>不会影响程序运行:<br><img src=\"/2024/06/03/Spark3/16.jpg\"><br>当新的master接收集群后, 程序继续运行, 正常得到结果.</p>\n<blockquote>\n<p>结论 HA模式下, 主备切换 不会影响到正在运行的程序.</p>\n<p>最大的影响是 会让它中断大约30秒左右.</p>\n</blockquote>\n<h1 id=\"Spark-On-YARN-环境搭建\"><a href=\"#Spark-On-YARN-环境搭建\" class=\"headerlink\" title=\"Spark On YARN 环境搭建\"></a>Spark On YARN 环境搭建</h1><h2 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h2><p>确保:</p>\n<ul>\n<li>HADOOP_CONF_DIR</li>\n<li>YARN_CONF_DIR</li>\n</ul>\n<p>在spark-env.sh 以及 环境变量配置文件中即可<br>​</p>\n<h2 id=\"连接到YARN中\"><a href=\"#连接到YARN中\" class=\"headerlink\" title=\"连接到YARN中\"></a>连接到YARN中</h2><h3 id=\"bin-pyspark\"><a href=\"#bin-pyspark\" class=\"headerlink\" title=\"bin&#x2F;pyspark\"></a>bin&#x2F;pyspark</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/pyspark --master yarn --deploy-mode client|cluster</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">--deploy-mode 选项是指定部署模式, 默认是 客户端模式</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">client就是客户端模式</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">cluster就是集群模式</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">--deploy-mode 仅可以用在YARN模式下</span></span><br></pre></td></tr></table></figure>\n\n\n<blockquote>\n<p>注意: 交互式环境 pyspark  和 spark-shell  无法运行 cluster模式</p>\n</blockquote>\n<h3 id=\"bin-spark-shell\"><a href=\"#bin-spark-shell\" class=\"headerlink\" title=\"bin&#x2F;spark-shell\"></a>bin&#x2F;spark-shell</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/spark-shell --master yarn --deploy-mode client|cluster</span><br></pre></td></tr></table></figure>\n\n\n<blockquote>\n<p>注意: 交互式环境 pyspark  和 spark-shell  无法运行 cluster模式</p>\n</blockquote>\n<h3 id=\"bin-spark-submit-PI\"><a href=\"#bin-spark-submit-PI\" class=\"headerlink\" title=\"bin&#x2F;spark-submit (PI)\"></a>bin&#x2F;spark-submit (PI)</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/spark-submit --master yarn --deploy-mode client|cluster /xxx/xxx/xxx.py 参数</span><br></pre></td></tr></table></figure>\n\n\n<h2 id=\"spark-submit-和-spark-shell-和-pyspark的相关参数\"><a href=\"#spark-submit-和-spark-shell-和-pyspark的相关参数\" class=\"headerlink\" title=\"spark-submit 和 spark-shell 和 pyspark的相关参数\"></a>spark-submit 和 spark-shell 和 pyspark的相关参数</h2><p>参见: 附2<br>​</p>\n<h1 id=\"附1-Anaconda-On-Linux-安装-单台服务器\"><a href=\"#附1-Anaconda-On-Linux-安装-单台服务器\" class=\"headerlink\" title=\"附1 Anaconda On Linux 安装 (单台服务器)\"></a>附1 Anaconda On Linux 安装 (单台服务器)</h1><h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>上传安装包:</p>\n<p>上传: 资料中提供的<code>Anaconda3-2021.05-Linux-x86_64.sh</code>文件到Linux服务器上</p>\n<p>安装:</p>\n<p><code>sh ./Anaconda3-2021.05-Linux-x86_64.sh</code><br><img src=\"/2024/06/03/Spark3/17.jpg\"><br><img src=\"/2024/06/03/Spark3/18.jpg\"><br><img src=\"/2024/06/03/Spark3/19.jpg\"><br><img src=\"/2024/06/03/Spark3/20.jpg\"><br><img src=\"/2024/06/03/Spark3/21.jpg\"><br>输入yes后就安装完成了.</p>\n<p>安装完成后, <code>退出finalshell 重新进来</code>:<br><img src=\"/2024/06/03/Spark3/22.jpg\"></p>\n<p>看到这个Base开头表明安装好了.</p>\n<p>base是默认的虚拟环境.<br>​</p>\n<h2 id=\"国内源\"><a href=\"#国内源\" class=\"headerlink\" title=\"国内源\"></a>国内源</h2><p>如果你安装好后, 没有出现base, 可以打开:&#x2F;root&#x2F;.condarc这个文件, 追加如下内容:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">channels:</span><br><span class=\"line\">  - defaults</span><br><span class=\"line\">show_channel_urls: true</span><br><span class=\"line\">default_channels:</span><br><span class=\"line\">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class=\"line\">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class=\"line\">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class=\"line\">custom_channels:</span><br><span class=\"line\">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"附2-spark-submit和pyspark相关参数\"><a href=\"#附2-spark-submit和pyspark相关参数\" class=\"headerlink\" title=\"附2 spark-submit和pyspark相关参数\"></a>附2 spark-submit和pyspark相关参数</h1><p>客户端工具我们可以用的有:</p>\n<ul>\n<li>bin&#x2F;pyspark: pyspark解释器spark环境</li>\n<li>bin&#x2F;spark-shell: scala解释器spark环境</li>\n<li>bin&#x2F;spark-submit: 提交jar包或Python文件执行的工具</li>\n<li>bin&#x2F;spark-sql: sparksql客户端工具</li>\n</ul>\n<p>这4个客户端工具的参数基本通用.</p>\n<p>以spark-submit 为例:</p>\n<p><code>bin/spark-submit --master spark://node1:7077 xxx.py</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Usage: spark-submit [options] &lt;app jar | python file | R file&gt; [app arguments]</span><br><span class=\"line\">Usage: spark-submit --kill [submission ID] --master [spark://...]</span><br><span class=\"line\">Usage: spark-submit --status [submission ID] --master [spark://...]</span><br><span class=\"line\">Usage: spark-submit run-example [options] example-class [example args]</span><br><span class=\"line\"></span><br><span class=\"line\">Options:</span><br><span class=\"line\">  --master MASTER_URL         spark://host:port, mesos://host:port, yarn,</span><br><span class=\"line\">                              k8s://https://host:port, or local (Default: local[*]).</span><br><span class=\"line\">  --deploy-mode DEPLOY_MODE   部署模式 client 或者 cluster 默认是client</span><br><span class=\"line\">  --class CLASS_NAME          运行java或者scala class(for Java / Scala apps).</span><br><span class=\"line\">  --name NAME                 程序的名字</span><br><span class=\"line\">  --jars JARS                 Comma-separated list of jars to include on the driver</span><br><span class=\"line\">                              and executor classpaths.</span><br><span class=\"line\">  --packages                  Comma-separated list of maven coordinates of jars to include</span><br><span class=\"line\">                              on the driver and executor classpaths. Will search the local</span><br><span class=\"line\">                              maven repo, then maven central and any additional remote</span><br><span class=\"line\">                              repositories given by --repositories. The format for the</span><br><span class=\"line\">                              coordinates should be groupId:artifactId:version.</span><br><span class=\"line\">  --exclude-packages          Comma-separated list of groupId:artifactId, to exclude while</span><br><span class=\"line\">                              resolving the dependencies provided in --packages to avoid</span><br><span class=\"line\">                              dependency conflicts.</span><br><span class=\"line\">  --repositories              Comma-separated list of additional remote repositories to</span><br><span class=\"line\">                              search for the maven coordinates given with --packages.</span><br><span class=\"line\">  --py-files PY_FILES         指定Python程序依赖的其它python文件</span><br><span class=\"line\">  --files FILES               Comma-separated list of files to be placed in the working</span><br><span class=\"line\">                              directory of each executor. File paths of these files</span><br><span class=\"line\">                              in executors can be accessed via SparkFiles.get(fileName).</span><br><span class=\"line\">  --archives ARCHIVES         Comma-separated list of archives to be extracted into the</span><br><span class=\"line\">                              working directory of each executor.</span><br><span class=\"line\"></span><br><span class=\"line\">  --conf, -c PROP=VALUE       手动指定配置</span><br><span class=\"line\">  --properties-file FILE      Path to a file from which to load extra properties. If not</span><br><span class=\"line\">                              specified, this will look for conf/spark-defaults.conf.</span><br><span class=\"line\"></span><br><span class=\"line\">  --driver-memory MEM         Driver的可用内存(Default: 1024M).</span><br><span class=\"line\">  --driver-java-options       Driver的一些Java选项</span><br><span class=\"line\">  --driver-library-path       Extra library path entries to pass to the driver.</span><br><span class=\"line\">  --driver-class-path         Extra class path entries to pass to the driver. Note that</span><br><span class=\"line\">                              jars added with --jars are automatically included in the</span><br><span class=\"line\">                              classpath.</span><br><span class=\"line\"></span><br><span class=\"line\">  --executor-memory MEM       Executor的内存 (Default: 1G).</span><br><span class=\"line\"></span><br><span class=\"line\">  --proxy-user NAME           User to impersonate when submitting the application.</span><br><span class=\"line\">                              This argument does not work with --principal / --keytab.</span><br><span class=\"line\"></span><br><span class=\"line\">  --help, -h                  显示帮助文件</span><br><span class=\"line\">  --verbose, -v               Print additional debug output.</span><br><span class=\"line\">  --version,                  打印版本</span><br><span class=\"line\"></span><br><span class=\"line\"> Cluster deploy mode only(集群模式专属):</span><br><span class=\"line\">  --driver-cores NUM          Driver可用的的CPU核数(Default: 1).</span><br><span class=\"line\"></span><br><span class=\"line\"> Spark standalone or Mesos with cluster deploy mode only:</span><br><span class=\"line\">  --supervise                 如果给定, 可以尝试重启Driver</span><br><span class=\"line\"></span><br><span class=\"line\"> Spark standalone, Mesos or K8s with cluster deploy mode only:</span><br><span class=\"line\">  --kill SUBMISSION_ID        指定程序ID kill</span><br><span class=\"line\">  --status SUBMISSION_ID      指定程序ID 查看运行状态</span><br><span class=\"line\"></span><br><span class=\"line\"> Spark standalone, Mesos and Kubernetes only:</span><br><span class=\"line\">  --total-executor-cores NUM  整个任务可以给Executor多少个CPU核心用</span><br><span class=\"line\"></span><br><span class=\"line\"> Spark standalone, YARN and Kubernetes only:</span><br><span class=\"line\">  --executor-cores NUM        单个Executor能使用多少CPU核心</span><br><span class=\"line\"></span><br><span class=\"line\"> Spark on YARN and Kubernetes only(YARN模式下):</span><br><span class=\"line\">  --num-executors NUM         Executor应该开启几个</span><br><span class=\"line\">  --principal PRINCIPAL       Principal to be used to login to KDC.</span><br><span class=\"line\">  --keytab KEYTAB             The full path to the file that contains the keytab for the</span><br><span class=\"line\">                              principal specified above.</span><br><span class=\"line\"></span><br><span class=\"line\"> Spark on YARN only:</span><br><span class=\"line\">  --queue QUEUE_NAME          指定运行的YARN队列(Default: &quot;default&quot;).</span><br></pre></td></tr></table></figure>\n\n\n\n\n<h1 id=\"附3-Windows系统配置Anaconda\"><a href=\"#附3-Windows系统配置Anaconda\" class=\"headerlink\" title=\"附3 Windows系统配置Anaconda\"></a>附3 Windows系统配置Anaconda</h1><h2 id=\"安装-1\"><a href=\"#安装-1\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>打开资料中提供的:Anaconda3-2021.05-Windows-x86_64.exe文件,或者去官网下载:[<a href=\"https://www.anaconda.com/products/individual#Downloads]\">https://www.anaconda.com/products/individual#Downloads]</a><br>​</p>\n<p>打开后,一直点击<code>Next</code>下一步即可:<br><img src=\"/2024/06/03/Spark3/23.jpg\" alt=\"image.png\"><br><img src=\"/2024/06/03/Spark3/24.jpg\" alt=\"image.png\"><br>如果想要修改安装路径, 可以修改<br><img src=\"/2024/06/03/Spark3/25.jpg\" alt=\"image.png\"><br>不必勾选<br><img src=\"/2024/06/03/Spark3/26.jpg\" alt=\"image.png\"><br>最终点击Finish完成安装</p>\n<p>打开开始菜单, 搜索Anaconda<br><img src=\"/2024/06/03/Spark3/27.jpg\" alt=\"image.png\"><br>出现如图的程序, 安装成功.</p>\n<p>打开 <code>Anaconda Prompt</code>程序:<br><img src=\"/2024/06/03/Spark3/28.jpg\" alt=\"image.png\"><br>出现<code>base</code>说明安装正确.</p>\n<h2 id=\"配置国内源\"><a href=\"#配置国内源\" class=\"headerlink\" title=\"配置国内源\"></a>配置国内源</h2><p>Anaconda默认源服务器在国外, 网速比较慢, 配置国内源加速网络下载.<br>​</p>\n<p>打开上图中的 <code>Anaconda Prompt</code>程序:<br>执行:<br><code>conda config --set show_channel_urls yes</code><br>​</p>\n<p>然后用记事本打开:<br><code>C:\\Users\\用户名\\.condarc</code>文件, 将如下内容替换进文件内,保存即可:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">channels:</span><br><span class=\"line\">  - defaults</span><br><span class=\"line\">show_channel_urls: true</span><br><span class=\"line\">default_channels:</span><br><span class=\"line\">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class=\"line\">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class=\"line\">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class=\"line\">custom_channels:</span><br><span class=\"line\">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br></pre></td></tr></table></figure>\n\n\n<h2 id=\"创建虚拟环境\"><a href=\"#创建虚拟环境\" class=\"headerlink\" title=\"创建虚拟环境\"></a>创建虚拟环境</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">创建虚拟环境 pyspark, 基于Python 3.8</span></span><br><span class=\"line\">conda activate base </span><br><span class=\"line\">conda create -n pyspark python=3.8</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">切换到虚拟环境内</span></span><br><span class=\"line\">conda activate pyspark</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">在虚拟环境内安装包</span></span><br><span class=\"line\">pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple </span><br><span class=\"line\"></span><br><span class=\"line\">pip install pyspark==3.2.0 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>\n\n","slug":"Spark3","updated":"2024-06-04T03:09:24.000Z","comments":true,"permalink":"http://example.com/2024/06/03/Spark3/","tags":[{"name":"Spark(HA)，Spark(Yarn)","slug":"Spark-HA-，Spark-Yarn","permalink":"http://example.com/tags/Spark-HA-%EF%BC%8CSpark-Yarn/"}]},{"title":"Spark local& stand-alone 配置","date":"2024-06-03T05:31:31.000Z","path":"2024/06/03/Spark2/","text":"Spark Local环境部署下载地址https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz 条件 PYTHON 推荐3.8 JDK 1.8 Anaconda On Linux 安装本次课程的Python环境需要安装到Linux(虚拟机)和Windows(本机)上 参见最下方, 附1: Anaconda On Linux 安装 解压解压下载的Spark安装包 tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/ 环境变量配置Spark由如下5个环境变量需要设置 SPARK_HOME: 表示Spark安装路径在哪里 PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器 JAVA_HOME: 告知Spark Java在哪里 HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里 HADOOP_HOME: 告知Spark Hadoop安装在哪里 这5个环境变量 都需要配置在: /etc/profile中​ PYSPARK_PYTHON和 JAVA_HOME 需要同样配置在: /root/.bashrc中 上传Spark安装包资料中提供了: spark-3.2.0-bin-hadoop3.2.tgz 上传这个文件到Linux服务器中 将其解压, 课程中将其解压(安装)到: /export/server内. tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/ 由于spark目录名称很长, 给其一个软链接: ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark​ 测试bin&#x2F;pysparkbin&#x2F;pyspark 程序, 可以提供一个 交互式的 Python解释器环境, 在这里面可以写普通python代码, 以及spark代码​ 如图: 在这个环境内, 可以运行spark代码 图中的: parallelize 和 map 都是spark提供的API sc.parallelize([1,2,3,4,5]).map(lambda x: x + 1).collect()​ WEB UI (4040)Spark程序在运行的时候, 会绑定到机器的4040端口上. 如果4040端口被占用, 会顺延到4041 … 4042… 4040端口是一个WEBUI端口, 可以在浏览器内打开: 输入:服务器ip:4040 即可打开: 打开监控页面后, 可以发现 在程序内仅有一个Driver 因为我们是Local模式, Driver即管理 又 干活. 同时, 输入jps​ 可以看到local模式下的唯一进程存在 这个进程 即是master也是worker bin&#x2F;spark-shell - 了解同样是一个解释器环境, 和bin/pyspark不同的是, 这个解释器环境 运行的不是python代码, 而是scala程序代码 12scala&gt; sc.parallelize(Array(1,2,3,4,5)).map(x=&gt; x + 1).collect()res0: Array[Int] = Array(2, 3, 4, 5, 6) 这个仅作为了解即可, 因为这个是用于scala语言的解释器环境 bin&#x2F;spark-submit (PI)作用: 提交指定的Spark代码到Spark环境中运行 使用方法: 123456# 语法bin/spark-submit [可选的一些选项] jar包或者python代码的路径 [代码的参数]# 示例bin/spark-submit /export/server/spark/examples/src/main/python/pi.py 10# 此案例 运行Spark官方所提供的示例代码 来计算圆周率值. 后面的10 是主函数接受的参数, 数字越高, 计算圆周率越准确. 对比 功能 bin&#x2F;spark-submit bin&#x2F;pyspark bin&#x2F;spark-shell 功能 提交java\\scala\\python代码到spark中运行 提供一个python 解释器环境用来以python代码执行spark程序 提供一个scala 解释器环境用来以scala代码执行spark程序 特点 提交代码用 解释器环境 写一行执行一行 解释器环境 写一行执行一行 使用场景 正式场合, 正式提交spark程序运行 测试\\学习\\写一行执行一行\\用来验证代码等 测试\\学习\\写一行执行一行\\用来验证代码等 Spark StandAlone环境部署新角色 历史服务器 历史服务器不是Spark环境的必要组件, 是可选的. 回忆: 在YARN中 有一个历史服务器, 功能: 将YARN运行的程序的历史日志记录下来, 通过历史服务器方便用户查看程序运行的历史信息. Spark的历史服务器, 功能: 将Spark运行的程序的历史日志记录下来, 通过历史服务器方便用户查看程序运行的历史信息. 搭建集群环境, 我们一般推荐将历史服务器也配置上, 方面以后查看历史记录​ 集群规划课程中 使用三台Linux虚拟机来组成集群环境, 非别是: node1\\ node2\\ node3 node1运行: Spark的Master进程 和 1个Worker进程 node2运行: spark的1个worker进程 node3运行: spark的1个worker进程 整个集群提供: 1个master进程 和 3个worker进程 安装在所有机器安装Python(Anaconda)参考 附1内容, 如何在Linux上安装anaconda 同时不要忘记 都创建pyspark虚拟环境 以及安装虚拟环境所需要的包pyspark jieba pyhive 在所有机器配置环境变量参考 Local模式下 环境变量的配置内容 确保3台都配置 配置配置文件进入到spark的配置文件目录中, cd $SPARK_HOME/conf 配置workers文件 123456789101112# 改名, 去掉后面的.template后缀mv workers.template workers# 编辑worker文件vim workers# 将里面的localhost删除, 追加node1node2node3到workers文件内# 功能: 这个文件就是指示了 当前SparkStandAlone环境下, 有哪些worker 配置spark-env.sh文件 1234567891011121314151617181920212223242526272829303132# 1. 改名mv spark-env.sh.template spark-env.sh# 2. 编辑spark-env.sh, 在底部追加如下内容## 设置JAVA安装目录JAVA_HOME=/export/server/jdk## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoopYARN_CONF_DIR=/export/server/hadoop/etc/hadoop## 指定spark老大Master的IP和提交任务的通信端口# 告知Spark的master运行在哪个机器上export SPARK_MASTER_HOST=node1# 告知sparkmaster的通讯端口export SPARK_MASTER_PORT=7077# 告知spark master的 webui端口SPARK_MASTER_WEBUI_PORT=8080# worker cpu可用核数SPARK_WORKER_CORES=1# worker可用内存SPARK_WORKER_MEMORY=1g# worker的工作通讯地址SPARK_WORKER_PORT=7078# worker的 webui地址SPARK_WORKER_WEBUI_PORT=8081## 设置历史服务器# 配置的意思是 将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node1:8020/sparklog/ -Dspark.history.fs.cleaner.enabled=true&quot; 注意, 上面的配置的路径 要根据你自己机器实际的路径来写 在HDFS上创建程序运行历史记录存放的文件夹: 12hadoop fs -mkdir /sparkloghadoop fs -chmod 777 /sparklog 配置spark-defaults.conf文件 12345678910# 1. 改名mv spark-defaults.conf.template spark-defaults.conf# 2. 修改内容, 追加如下内容# 开启spark的日期记录功能spark.eventLog.enabled true# 设置spark日志记录的路径spark.eventLog.dir hdfs://node1:8020/sparklog/ # 设置spark日志是否启动压缩spark.eventLog.compress true 配置log4j.properties 文件 [可选配置] 1234# 1. 改名mv log4j.properties.template log4j.properties# 2. 修改内容 参考下图 这个文件的修改不是必须的, 为什么修改为WARN. 因为Spark是个话痨 会疯狂输出日志, 设置级别为WARN 只输出警告和错误日志, 不要输出一堆废话. 将Spark安装文件夹 分发到其它的服务器上12scp -r spark-3.1.2-bin-hadoop3.2 root@node2:/export/server/scp -r spark-3.1.2-bin-hadoop3.2 root@node3:/export/server/ 不要忘记, 在node2和node3上 给spark安装目录增加软链接 ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark 检查检查每台机器的: JAVA_HOME SPARK_HOME PYSPARK_PYTHON 等等 环境变量是否正常指向正确的目录 启动历史服务器sbin/start-history-server.sh 启动Spark的Master和Worker进程1234567891011121314151617# 启动全部master和workersbin/start-all.sh# 或者可以一个个启动:# 启动当前机器的mastersbin/start-master.sh# 启动当前机器的workersbin/start-worker.sh# 停止全部sbin/stop-all.sh# 停止当前机器的mastersbin/stop-master.sh# 停止当前机器的workersbin/stop-worker.sh 查看Master的WEB UI默认端口master我们设置到了8080 如果端口被占用, 会顺延到8081 …;8082… 8083… 直到申请到端口为止 可以在日志中查看, 具体顺延到哪个端口上: Service &#39;MasterUI&#39; could not bind on port 8080. Attempting port 8081.​ 连接到StandAlone集群bin&#x2F;pyspark执行: 123456bin/pyspark --master spark://node1:7077# 通过--master选项来连接到 StandAlone集群# 如果不写--master选项, 默认是local模式运行sc.parallelize([1,2,3,4,5]).map(lambda x: x + 1).collect() bin&#x2F;spark-shell12bin/spark-shell --master spark://node1:7077# 同样适用--master来连接到集群使用 12// 测试代码sc.parallelize(Array(1,2,3,4,5)).map(x=&gt; x + 1).collect() bin&#x2F;spark-submit (PI)12bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 100# 同样使用--master来指定将任务提交到集群运行 查看历史服务器WEB UI历史服务器的默认端口是: 18080 我们启动在node1上, 可以在浏览器打开: node1:18080来进入到历史服务器的WEB UI上. zookeeper","raw":"---\ntitle: Spark local& stand-alone 配置\ndate: 2024-06-03 13:31:31\ntags: Spark(local)，Spark(stand-alone)\n---\n\n# Spark Local环境部署\n\n## 下载地址\n\nhttps://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n\n\n\n## 条件\n\n\n- PYTHON 推荐3.8\n- JDK 1.8\n\n\n\n## Anaconda On Linux 安装\n\n本次课程的Python环境需要安装到Linux(虚拟机)和Windows(本机)上\n\n参见最下方, 附1: Anaconda On Linux 安装\n\n\n\n## 解压\n\n解压下载的Spark安装包\n\n`tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/`\n\n\n\n## 环境变量\n\n\n配置Spark由如下5个环境变量需要设置\n\n\n-  SPARK_HOME: 表示Spark安装路径在哪里 \n-  PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器 \n-  JAVA_HOME: 告知Spark Java在哪里 \n-  HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里 \n-  HADOOP_HOME: 告知Spark  Hadoop安装在哪里 \n\n\n\n这5个环境变量 都需要配置在: `/etc/profile`中\n​\n\n![](/2024/06/03/Spark2/1.jpg)\n\n\nPYSPARK_PYTHON和 JAVA_HOME 需要同样配置在: `/root/.bashrc`中\n\n\n![](/2024/06/03/Spark2/2.jpg)\n\n## 上传Spark安装包\n\n\n资料中提供了: `spark-3.2.0-bin-hadoop3.2.tgz`\n\n\n上传这个文件到Linux服务器中\n\n\n将其解压, 课程中将其解压(安装)到: `/export/server`内.\n\n`tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/`\n\n\n由于spark目录名称很长, 给其一个软链接:\n\n`ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark`\n​\n\n![](/2024/06/03/Spark2/3.jpg)\n![](/2024/06/03/Spark2/4.jpg)\n\n\n## 测试\n\n\n### bin/pyspark\n\nbin/pyspark 程序, 可以提供一个  `交互式`的 Python解释器环境, 在这里面可以写普通python代码, 以及spark代码\n​\n\n![](/2024/06/03/Spark2/5.jpg)\n\n\n如图:\n\n\n![](/2024/06/03/Spark2/6.jpg)\n\n\n在这个环境内, 可以运行spark代码\n\n\n图中的: `parallelize` 和 `map` 都是spark提供的API\n\n`sc.parallelize([1,2,3,4,5]).map(lambda x: x + 1).collect()`\n​\n\n### WEB UI (4040)\n\n\nSpark程序在运行的时候, 会绑定到机器的`4040`端口上.\n\n如果4040端口被占用, 会顺延到4041 ... 4042...\n![](/2024/06/03/Spark2/7.jpg)\n\n\n4040端口是一个WEBUI端口, 可以在浏览器内打开:\n\n输入:`服务器ip:4040` 即可打开:\n![](/2024/06/03/Spark2/8.jpg)\n\n\n打开监控页面后, 可以发现 在程序内仅有一个Driver\n\n\n因为我们是Local模式, Driver即管理 又 干活.\n\n同时, 输入jps\n​\n\n![](/2024/06/03/Spark2/9.jpg)\n\n\n可以看到local模式下的唯一进程存在\n\n\n这个进程 即是master也是worker\n\n\n### bin/spark-shell - 了解\n\n\n同样是一个解释器环境, 和`bin/pyspark`不同的是, 这个解释器环境 运行的不是python代码, 而是scala程序代码\n\n\n```shell\nscala> sc.parallelize(Array(1,2,3,4,5)).map(x=> x + 1).collect()\nres0: Array[Int] = Array(2, 3, 4, 5, 6)\n```\n\n\n> 这个仅作为了解即可, 因为这个是用于scala语言的解释器环境\n\n\n\n### bin/spark-submit (PI)\n\n\n作用: 提交指定的Spark代码到Spark环境中运行\n\n\n使用方法:\n\n\n```shell\n# 语法\nbin/spark-submit [可选的一些选项] jar包或者python代码的路径 [代码的参数]\n\n# 示例\nbin/spark-submit /export/server/spark/examples/src/main/python/pi.py 10\n# 此案例 运行Spark官方所提供的示例代码 来计算圆周率值.  后面的10 是主函数接受的参数, 数字越高, 计算圆周率越准确.\n```\n\n\n对比\n\n| 功能 | bin/spark-submit | bin/pyspark | bin/spark-shell |\n| --- | --- | --- | --- |\n| 功能 | 提交java\\scala\\python代码到spark中运行 | 提供一个`python`\n解释器环境用来以python代码执行spark程序 | 提供一个`scala`\n解释器环境用来以scala代码执行spark程序 |\n| 特点 | 提交代码用 | 解释器环境 写一行执行一行 | 解释器环境 写一行执行一行 |\n| 使用场景 | 正式场合, 正式提交spark程序运行 | 测试\\学习\\写一行执行一行\\用来验证代码等 | 测试\\学习\\写一行执行一行\\用来验证代码等 |\n\n\n\n# Spark StandAlone环境部署\n\n## 新角色 历史服务器\n\n\n> 历史服务器不是Spark环境的必要组件, 是可选的.\n\n> 回忆: 在YARN中 有一个历史服务器, 功能: 将YARN运行的程序的历史日志记录下来, 通过历史服务器方便用户查看程序运行的历史信息.\n\n\n\nSpark的历史服务器, 功能: 将Spark运行的程序的历史日志记录下来, 通过历史服务器方便用户查看程序运行的历史信息.\n\n搭建集群环境, 我们一般`推荐将历史服务器也配置上`, 方面以后查看历史记录\n​\n\n## 集群规划\n\n\n课程中 使用三台Linux虚拟机来组成集群环境, 非别是:\n\n\nnode1\\ node2\\ node3\n\n\nnode1运行: Spark的Master进程  和 1个Worker进程\n\n\nnode2运行: spark的1个worker进程\n\n\nnode3运行: spark的1个worker进程\n\n\n整个集群提供: 1个master进程 和 3个worker进程\n\n\n## 安装\n\n\n### 在所有机器安装Python(Anaconda)\n\n\n参考 附1内容, 如何在Linux上安装anaconda\n\n\n同时不要忘记 都创建`pyspark`虚拟环境 以及安装虚拟环境所需要的包`pyspark jieba pyhive`\n\n\n### 在所有机器配置环境变量\n\n\n参考 Local模式下 环境变量的配置内容\n\n\n`确保3台都配置`\n\n\n### 配置配置文件\n\n\n进入到spark的配置文件目录中, `cd $SPARK_HOME/conf`\n\n\n配置workers文件\n\n\n```shell\n# 改名, 去掉后面的.template后缀\nmv workers.template workers\n\n# 编辑worker文件\nvim workers\n# 将里面的localhost删除, 追加\nnode1\nnode2\nnode3\n到workers文件内\n\n# 功能: 这个文件就是指示了  当前SparkStandAlone环境下, 有哪些worker\n```\n\n\n配置spark-env.sh文件\n\n\n```shell\n# 1. 改名\nmv spark-env.sh.template spark-env.sh\n\n# 2. 编辑spark-env.sh, 在底部追加如下内容\n\n## 设置JAVA安装目录\nJAVA_HOME=/export/server/jdk\n\n## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群\nHADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop\nYARN_CONF_DIR=/export/server/hadoop/etc/hadoop\n\n## 指定spark老大Master的IP和提交任务的通信端口\n# 告知Spark的master运行在哪个机器上\nexport SPARK_MASTER_HOST=node1\n# 告知sparkmaster的通讯端口\nexport SPARK_MASTER_PORT=7077\n# 告知spark master的 webui端口\nSPARK_MASTER_WEBUI_PORT=8080\n\n# worker cpu可用核数\nSPARK_WORKER_CORES=1\n# worker可用内存\nSPARK_WORKER_MEMORY=1g\n# worker的工作通讯地址\nSPARK_WORKER_PORT=7078\n# worker的 webui地址\nSPARK_WORKER_WEBUI_PORT=8081\n\n## 设置历史服务器\n# 配置的意思是  将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中\nSPARK_HISTORY_OPTS=\"-Dspark.history.fs.logDirectory=hdfs://node1:8020/sparklog/ -Dspark.history.fs.cleaner.enabled=true\"\n```\n\n\n注意, 上面的配置的路径 要根据你自己机器实际的路径来写\n\n\n在HDFS上创建程序运行历史记录存放的文件夹:\n\n\n```shell\nhadoop fs -mkdir /sparklog\nhadoop fs -chmod 777 /sparklog\n```\n\n\n配置spark-defaults.conf文件\n\n\n```shell\n# 1. 改名\nmv spark-defaults.conf.template spark-defaults.conf\n\n# 2. 修改内容, 追加如下内容\n# 开启spark的日期记录功能\nspark.eventLog.enabled \ttrue\n# 设置spark日志记录的路径\nspark.eventLog.dir\t hdfs://node1:8020/sparklog/ \n# 设置spark日志是否启动压缩\nspark.eventLog.compress \ttrue\n```\n\n\n配置log4j.properties 文件 [可选配置]\n\n\n```shell\n# 1. 改名\nmv log4j.properties.template log4j.properties\n\n# 2. 修改内容 参考下图\n```\n\n![](/2024/06/03/Spark2/10.jpg)\n\n> 这个文件的修改不是必须的,  为什么修改为WARN. 因为Spark是个话痨\n>\n> 会疯狂输出日志, 设置级别为WARN 只输出警告和错误日志, 不要输出一堆废话.\n\n\n\n### 将Spark安装文件夹  分发到其它的服务器上\n\n\n```shell\nscp -r spark-3.1.2-bin-hadoop3.2 root@node2:/export/server/\nscp -r spark-3.1.2-bin-hadoop3.2 root@node3:/export/server/\n```\n\n\n不要忘记, 在node2和node3上 给spark安装目录增加软链接\n\n`ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark`\n\n\n### 检查\n\n\n检查每台机器的:\n\n\nJAVA_HOME\n\n\nSPARK_HOME\n\n\nPYSPARK_PYTHON\n\n\n等等 环境变量是否正常指向正确的目录\n\n\n### 启动历史服务器\n\n`sbin/start-history-server.sh`\n\n\n### 启动Spark的Master和Worker进程\n\n\n```shell\n# 启动全部master和worker\nsbin/start-all.sh\n\n# 或者可以一个个启动:\n# 启动当前机器的master\nsbin/start-master.sh\n# 启动当前机器的worker\nsbin/start-worker.sh\n\n# 停止全部\nsbin/stop-all.sh\n\n# 停止当前机器的master\nsbin/stop-master.sh\n\n# 停止当前机器的worker\nsbin/stop-worker.sh\n```\n\n\n### 查看Master的WEB UI\n\n\n默认端口master我们设置到了8080\n\n\n如果端口被占用, 会顺延到8081 ...;8082... 8083... 直到申请到端口为止\n\n\n可以在日志中查看, 具体顺延到哪个端口上:\n\n\n`Service 'MasterUI' could not bind on port 8080. Attempting port 8081.`\n​\n\n\n\n![](/2024/06/03/Spark2/11.jpg)\n\n\n### 连接到StandAlone集群\n\n\n#### bin/pyspark\n\n\n执行:\n\n\n```shell\nbin/pyspark --master spark://node1:7077\n# 通过--master选项来连接到 StandAlone集群\n# 如果不写--master选项, 默认是local模式运行\n\n\nsc.parallelize([1,2,3,4,5]).map(lambda x: x + 1).collect()\n```\n\n![](/2024/06/03/Spark2/12.jpg)\n\n\n#### bin/spark-shell\n\n\n```shell\nbin/spark-shell --master spark://node1:7077\n# 同样适用--master来连接到集群使用\n```\n\n\n```scala\n// 测试代码\nsc.parallelize(Array(1,2,3,4,5)).map(x=> x + 1).collect()\n```\n\n\n#### bin/spark-submit (PI)\n\n\n```shell\nbin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 100\n# 同样使用--master来指定将任务提交到集群运行\n```\n\n\n### 查看历史服务器WEB UI\n\n\n历史服务器的默认端口是: 18080\n\n\n我们启动在node1上, 可以在浏览器打开:\n\n`node1:18080`来进入到历史服务器的WEB UI上.\n![](/2024/06/03/Spark2/13.jpg)\n\nzookeeper","content":"<h1 id=\"Spark-Local环境部署\"><a href=\"#Spark-Local环境部署\" class=\"headerlink\" title=\"Spark Local环境部署\"></a>Spark Local环境部署</h1><h2 id=\"下载地址\"><a href=\"#下载地址\" class=\"headerlink\" title=\"下载地址\"></a>下载地址</h2><p><a href=\"https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\">https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz</a></p>\n<h2 id=\"条件\"><a href=\"#条件\" class=\"headerlink\" title=\"条件\"></a>条件</h2><ul>\n<li>PYTHON 推荐3.8</li>\n<li>JDK 1.8</li>\n</ul>\n<h2 id=\"Anaconda-On-Linux-安装\"><a href=\"#Anaconda-On-Linux-安装\" class=\"headerlink\" title=\"Anaconda On Linux 安装\"></a>Anaconda On Linux 安装</h2><p>本次课程的Python环境需要安装到Linux(虚拟机)和Windows(本机)上</p>\n<p>参见最下方, 附1: Anaconda On Linux 安装</p>\n<h2 id=\"解压\"><a href=\"#解压\" class=\"headerlink\" title=\"解压\"></a>解压</h2><p>解压下载的Spark安装包</p>\n<p><code>tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/</code></p>\n<h2 id=\"环境变量\"><a href=\"#环境变量\" class=\"headerlink\" title=\"环境变量\"></a>环境变量</h2><p>配置Spark由如下5个环境变量需要设置</p>\n<ul>\n<li>SPARK_HOME: 表示Spark安装路径在哪里 </li>\n<li>PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器 </li>\n<li>JAVA_HOME: 告知Spark Java在哪里 </li>\n<li>HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里 </li>\n<li>HADOOP_HOME: 告知Spark  Hadoop安装在哪里</li>\n</ul>\n<p>这5个环境变量 都需要配置在: <code>/etc/profile</code>中<br>​</p>\n<p><img src=\"/2024/06/03/Spark2/1.jpg\"></p>\n<p>PYSPARK_PYTHON和 JAVA_HOME 需要同样配置在: <code>/root/.bashrc</code>中</p>\n<p><img src=\"/2024/06/03/Spark2/2.jpg\"></p>\n<h2 id=\"上传Spark安装包\"><a href=\"#上传Spark安装包\" class=\"headerlink\" title=\"上传Spark安装包\"></a>上传Spark安装包</h2><p>资料中提供了: <code>spark-3.2.0-bin-hadoop3.2.tgz</code></p>\n<p>上传这个文件到Linux服务器中</p>\n<p>将其解压, 课程中将其解压(安装)到: <code>/export/server</code>内.</p>\n<p><code>tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/</code></p>\n<p>由于spark目录名称很长, 给其一个软链接:</p>\n<p><code>ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark</code><br>​</p>\n<p><img src=\"/2024/06/03/Spark2/3.jpg\"><br><img src=\"/2024/06/03/Spark2/4.jpg\"></p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2><h3 id=\"bin-pyspark\"><a href=\"#bin-pyspark\" class=\"headerlink\" title=\"bin&#x2F;pyspark\"></a>bin&#x2F;pyspark</h3><p>bin&#x2F;pyspark 程序, 可以提供一个  <code>交互式</code>的 Python解释器环境, 在这里面可以写普通python代码, 以及spark代码<br>​</p>\n<p><img src=\"/2024/06/03/Spark2/5.jpg\"></p>\n<p>如图:</p>\n<p><img src=\"/2024/06/03/Spark2/6.jpg\"></p>\n<p>在这个环境内, 可以运行spark代码</p>\n<p>图中的: <code>parallelize</code> 和 <code>map</code> 都是spark提供的API</p>\n<p><code>sc.parallelize([1,2,3,4,5]).map(lambda x: x + 1).collect()</code><br>​</p>\n<h3 id=\"WEB-UI-4040\"><a href=\"#WEB-UI-4040\" class=\"headerlink\" title=\"WEB UI (4040)\"></a>WEB UI (4040)</h3><p>Spark程序在运行的时候, 会绑定到机器的<code>4040</code>端口上.</p>\n<p>如果4040端口被占用, 会顺延到4041 … 4042…<br><img src=\"/2024/06/03/Spark2/7.jpg\"></p>\n<p>4040端口是一个WEBUI端口, 可以在浏览器内打开:</p>\n<p>输入:<code>服务器ip:4040</code> 即可打开:<br><img src=\"/2024/06/03/Spark2/8.jpg\"></p>\n<p>打开监控页面后, 可以发现 在程序内仅有一个Driver</p>\n<p>因为我们是Local模式, Driver即管理 又 干活.</p>\n<p>同时, 输入jps<br>​</p>\n<p><img src=\"/2024/06/03/Spark2/9.jpg\"></p>\n<p>可以看到local模式下的唯一进程存在</p>\n<p>这个进程 即是master也是worker</p>\n<h3 id=\"bin-spark-shell-了解\"><a href=\"#bin-spark-shell-了解\" class=\"headerlink\" title=\"bin&#x2F;spark-shell - 了解\"></a>bin&#x2F;spark-shell - 了解</h3><p>同样是一个解释器环境, 和<code>bin/pyspark</code>不同的是, 这个解释器环境 运行的不是python代码, 而是scala程序代码</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">scala&gt; </span><span class=\"language-bash\">sc.parallelize(Array(1,2,3,4,5)).map(x=&gt; x + 1).collect()</span></span><br><span class=\"line\">res0: Array[Int] = Array(2, 3, 4, 5, 6)</span><br></pre></td></tr></table></figure>\n\n\n<blockquote>\n<p>这个仅作为了解即可, 因为这个是用于scala语言的解释器环境</p>\n</blockquote>\n<h3 id=\"bin-spark-submit-PI\"><a href=\"#bin-spark-submit-PI\" class=\"headerlink\" title=\"bin&#x2F;spark-submit (PI)\"></a>bin&#x2F;spark-submit (PI)</h3><p>作用: 提交指定的Spark代码到Spark环境中运行</p>\n<p>使用方法:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">语法</span></span><br><span class=\"line\">bin/spark-submit [可选的一些选项] jar包或者python代码的路径 [代码的参数]</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">示例</span></span><br><span class=\"line\">bin/spark-submit /export/server/spark/examples/src/main/python/pi.py 10</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">此案例 运行Spark官方所提供的示例代码 来计算圆周率值.  后面的10 是主函数接受的参数, 数字越高, 计算圆周率越准确.</span></span><br></pre></td></tr></table></figure>\n\n\n<p>对比</p>\n<table>\n<thead>\n<tr>\n<th>功能</th>\n<th>bin&#x2F;spark-submit</th>\n<th>bin&#x2F;pyspark</th>\n<th>bin&#x2F;spark-shell</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>功能</td>\n<td>提交java\\scala\\python代码到spark中运行</td>\n<td>提供一个<code>python</code></td>\n<td></td>\n</tr>\n<tr>\n<td>解释器环境用来以python代码执行spark程序</td>\n<td>提供一个<code>scala</code></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>解释器环境用来以scala代码执行spark程序</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>特点</td>\n<td>提交代码用</td>\n<td>解释器环境 写一行执行一行</td>\n<td>解释器环境 写一行执行一行</td>\n</tr>\n<tr>\n<td>使用场景</td>\n<td>正式场合, 正式提交spark程序运行</td>\n<td>测试\\学习\\写一行执行一行\\用来验证代码等</td>\n<td>测试\\学习\\写一行执行一行\\用来验证代码等</td>\n</tr>\n</tbody></table>\n<h1 id=\"Spark-StandAlone环境部署\"><a href=\"#Spark-StandAlone环境部署\" class=\"headerlink\" title=\"Spark StandAlone环境部署\"></a>Spark StandAlone环境部署</h1><h2 id=\"新角色-历史服务器\"><a href=\"#新角色-历史服务器\" class=\"headerlink\" title=\"新角色 历史服务器\"></a>新角色 历史服务器</h2><blockquote>\n<p>历史服务器不是Spark环境的必要组件, 是可选的.</p>\n</blockquote>\n<blockquote>\n<p>回忆: 在YARN中 有一个历史服务器, 功能: 将YARN运行的程序的历史日志记录下来, 通过历史服务器方便用户查看程序运行的历史信息.</p>\n</blockquote>\n<p>Spark的历史服务器, 功能: 将Spark运行的程序的历史日志记录下来, 通过历史服务器方便用户查看程序运行的历史信息.</p>\n<p>搭建集群环境, 我们一般<code>推荐将历史服务器也配置上</code>, 方面以后查看历史记录<br>​</p>\n<h2 id=\"集群规划\"><a href=\"#集群规划\" class=\"headerlink\" title=\"集群规划\"></a>集群规划</h2><p>课程中 使用三台Linux虚拟机来组成集群环境, 非别是:</p>\n<p>node1\\ node2\\ node3</p>\n<p>node1运行: Spark的Master进程  和 1个Worker进程</p>\n<p>node2运行: spark的1个worker进程</p>\n<p>node3运行: spark的1个worker进程</p>\n<p>整个集群提供: 1个master进程 和 3个worker进程</p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><h3 id=\"在所有机器安装Python-Anaconda\"><a href=\"#在所有机器安装Python-Anaconda\" class=\"headerlink\" title=\"在所有机器安装Python(Anaconda)\"></a>在所有机器安装Python(Anaconda)</h3><p>参考 附1内容, 如何在Linux上安装anaconda</p>\n<p>同时不要忘记 都创建<code>pyspark</code>虚拟环境 以及安装虚拟环境所需要的包<code>pyspark jieba pyhive</code></p>\n<h3 id=\"在所有机器配置环境变量\"><a href=\"#在所有机器配置环境变量\" class=\"headerlink\" title=\"在所有机器配置环境变量\"></a>在所有机器配置环境变量</h3><p>参考 Local模式下 环境变量的配置内容</p>\n<p><code>确保3台都配置</code></p>\n<h3 id=\"配置配置文件\"><a href=\"#配置配置文件\" class=\"headerlink\" title=\"配置配置文件\"></a>配置配置文件</h3><p>进入到spark的配置文件目录中, <code>cd $SPARK_HOME/conf</code></p>\n<p>配置workers文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">改名, 去掉后面的.template后缀</span></span><br><span class=\"line\">mv workers.template workers</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">编辑worker文件</span></span><br><span class=\"line\">vim workers</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">将里面的localhost删除, 追加</span></span><br><span class=\"line\">node1</span><br><span class=\"line\">node2</span><br><span class=\"line\">node3</span><br><span class=\"line\">到workers文件内</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">功能: 这个文件就是指示了  当前SparkStandAlone环境下, 有哪些worker</span></span><br></pre></td></tr></table></figure>\n\n\n<p>配置spark-env.sh文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">1. 改名</span></span><br><span class=\"line\">mv spark-env.sh.template spark-env.sh</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">2. 编辑spark-env.sh, 在底部追加如下内容</span></span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\"><span class=\"comment\"># 设置JAVA安装目录</span></span></span><br><span class=\"line\">JAVA_HOME=/export/server/jdk</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\"><span class=\"comment\"># HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群</span></span></span><br><span class=\"line\">HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class=\"line\">YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\"><span class=\"comment\"># 指定spark老大Master的IP和提交任务的通信端口</span></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">告知Spark的master运行在哪个机器上</span></span><br><span class=\"line\">export SPARK_MASTER_HOST=node1</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">告知sparkmaster的通讯端口</span></span><br><span class=\"line\">export SPARK_MASTER_PORT=7077</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">告知spark master的 webui端口</span></span><br><span class=\"line\">SPARK_MASTER_WEBUI_PORT=8080</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">worker cpu可用核数</span></span><br><span class=\"line\">SPARK_WORKER_CORES=1</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">worker可用内存</span></span><br><span class=\"line\">SPARK_WORKER_MEMORY=1g</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">worker的工作通讯地址</span></span><br><span class=\"line\">SPARK_WORKER_PORT=7078</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">worker的 webui地址</span></span><br><span class=\"line\">SPARK_WORKER_WEBUI_PORT=8081</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\"><span class=\"comment\"># 设置历史服务器</span></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">配置的意思是  将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中</span></span><br><span class=\"line\">SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node1:8020/sparklog/ -Dspark.history.fs.cleaner.enabled=true&quot;</span><br></pre></td></tr></table></figure>\n\n\n<p>注意, 上面的配置的路径 要根据你自己机器实际的路径来写</p>\n<p>在HDFS上创建程序运行历史记录存放的文件夹:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop fs -mkdir /sparklog</span><br><span class=\"line\">hadoop fs -chmod 777 /sparklog</span><br></pre></td></tr></table></figure>\n\n\n<p>配置spark-defaults.conf文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">1. 改名</span></span><br><span class=\"line\">mv spark-defaults.conf.template spark-defaults.conf</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">2. 修改内容, 追加如下内容</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">开启spark的日期记录功能</span></span><br><span class=\"line\">spark.eventLog.enabled \ttrue</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">设置spark日志记录的路径</span></span><br><span class=\"line\">spark.eventLog.dir\t hdfs://node1:8020/sparklog/ </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">设置spark日志是否启动压缩</span></span><br><span class=\"line\">spark.eventLog.compress \ttrue</span><br></pre></td></tr></table></figure>\n\n\n<p>配置log4j.properties 文件 [可选配置]</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">1. 改名</span></span><br><span class=\"line\">mv log4j.properties.template log4j.properties</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">2. 修改内容 参考下图</span></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/06/03/Spark2/10.jpg\"></p>\n<blockquote>\n<p>这个文件的修改不是必须的,  为什么修改为WARN. 因为Spark是个话痨</p>\n<p>会疯狂输出日志, 设置级别为WARN 只输出警告和错误日志, 不要输出一堆废话.</p>\n</blockquote>\n<h3 id=\"将Spark安装文件夹-分发到其它的服务器上\"><a href=\"#将Spark安装文件夹-分发到其它的服务器上\" class=\"headerlink\" title=\"将Spark安装文件夹  分发到其它的服务器上\"></a>将Spark安装文件夹  分发到其它的服务器上</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp -r spark-3.1.2-bin-hadoop3.2 root@node2:/export/server/</span><br><span class=\"line\">scp -r spark-3.1.2-bin-hadoop3.2 root@node3:/export/server/</span><br></pre></td></tr></table></figure>\n\n\n<p>不要忘记, 在node2和node3上 给spark安装目录增加软链接</p>\n<p><code>ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark</code></p>\n<h3 id=\"检查\"><a href=\"#检查\" class=\"headerlink\" title=\"检查\"></a>检查</h3><p>检查每台机器的:</p>\n<p>JAVA_HOME</p>\n<p>SPARK_HOME</p>\n<p>PYSPARK_PYTHON</p>\n<p>等等 环境变量是否正常指向正确的目录</p>\n<h3 id=\"启动历史服务器\"><a href=\"#启动历史服务器\" class=\"headerlink\" title=\"启动历史服务器\"></a>启动历史服务器</h3><p><code>sbin/start-history-server.sh</code></p>\n<h3 id=\"启动Spark的Master和Worker进程\"><a href=\"#启动Spark的Master和Worker进程\" class=\"headerlink\" title=\"启动Spark的Master和Worker进程\"></a>启动Spark的Master和Worker进程</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">启动全部master和worker</span></span><br><span class=\"line\">sbin/start-all.sh</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">或者可以一个个启动:</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">启动当前机器的master</span></span><br><span class=\"line\">sbin/start-master.sh</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">启动当前机器的worker</span></span><br><span class=\"line\">sbin/start-worker.sh</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">停止全部</span></span><br><span class=\"line\">sbin/stop-all.sh</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">停止当前机器的master</span></span><br><span class=\"line\">sbin/stop-master.sh</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">停止当前机器的worker</span></span><br><span class=\"line\">sbin/stop-worker.sh</span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"查看Master的WEB-UI\"><a href=\"#查看Master的WEB-UI\" class=\"headerlink\" title=\"查看Master的WEB UI\"></a>查看Master的WEB UI</h3><p>默认端口master我们设置到了8080</p>\n<p>如果端口被占用, 会顺延到8081 …;8082… 8083… 直到申请到端口为止</p>\n<p>可以在日志中查看, 具体顺延到哪个端口上:</p>\n<p><code>Service &#39;MasterUI&#39; could not bind on port 8080. Attempting port 8081.</code><br>​</p>\n<p><img src=\"/2024/06/03/Spark2/11.jpg\"></p>\n<h3 id=\"连接到StandAlone集群\"><a href=\"#连接到StandAlone集群\" class=\"headerlink\" title=\"连接到StandAlone集群\"></a>连接到StandAlone集群</h3><h4 id=\"bin-pyspark-1\"><a href=\"#bin-pyspark-1\" class=\"headerlink\" title=\"bin&#x2F;pyspark\"></a>bin&#x2F;pyspark</h4><p>执行:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/pyspark --master spark://node1:7077</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">通过--master选项来连接到 StandAlone集群</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">如果不写--master选项, 默认是<span class=\"built_in\">local</span>模式运行</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">sc.parallelize([1,2,3,4,5]).map(lambda x: x + 1).collect()</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/06/03/Spark2/12.jpg\"></p>\n<h4 id=\"bin-spark-shell\"><a href=\"#bin-spark-shell\" class=\"headerlink\" title=\"bin&#x2F;spark-shell\"></a>bin&#x2F;spark-shell</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/spark-shell --master spark://node1:7077</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">同样适用--master来连接到集群使用</span></span><br></pre></td></tr></table></figure>\n\n\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 测试代码</span></span><br><span class=\"line\">sc.parallelize(<span class=\"type\">Array</span>(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>)).map(x=&gt; x + <span class=\"number\">1</span>).collect()</span><br></pre></td></tr></table></figure>\n\n\n<h4 id=\"bin-spark-submit-PI-1\"><a href=\"#bin-spark-submit-PI-1\" class=\"headerlink\" title=\"bin&#x2F;spark-submit (PI)\"></a>bin&#x2F;spark-submit (PI)</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 100</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">同样使用--master来指定将任务提交到集群运行</span></span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"查看历史服务器WEB-UI\"><a href=\"#查看历史服务器WEB-UI\" class=\"headerlink\" title=\"查看历史服务器WEB UI\"></a>查看历史服务器WEB UI</h3><p>历史服务器的默认端口是: 18080</p>\n<p>我们启动在node1上, 可以在浏览器打开:</p>\n<p><code>node1:18080</code>来进入到历史服务器的WEB UI上.<br><img src=\"/2024/06/03/Spark2/13.jpg\"></p>\n<p>zookeeper</p>\n","slug":"Spark2","updated":"2024-06-04T03:09:24.000Z","comments":true,"permalink":"http://example.com/2024/06/03/Spark2/","tags":[{"name":"Spark(local)，Spark(stand-alone)","slug":"Spark-local-，Spark-stand-alone","permalink":"http://example.com/tags/Spark-local-%EF%BC%8CSpark-stand-alone/"}]},{"title":"Spark基础环境配置","date":"2024-06-03T04:56:35.000Z","path":"2024/06/03/Spark1/","text":"一、基础环境：1、主机名： 序号 主机名 IP Address 01 node1 192.168.88.151 02 node2 192.168.88.152 03 node3 192.168.88.153 2、配置hosts：（注：三台服务器同时配置） 测试：（每台服务器都测试） 3、安装NTP：（master做NTP服务器，slave1、slave2同步master）（1）matser： yum -y install ntp systemctl enable ntpd &amp;&amp; systemctl start ntpd 三台服务器需执行以上命令。 Server: Client: 检查：（master、slave1、slave2） 4、配置SSH免密码（1）所有节点分别生成私有密钥ssh-keygen -t dsa -P ‘’ -f &#x2F;root&#x2F;.ssh&#x2F;id_dsa （2）将公钥文件复制为authorized_keys文件 （3）mater主机连接自己，做SSH内环测试 （4）slave1、slave2节点将master公钥文件复制本机（注：密码验证） （5）将master节点公钥文件追加各个节点（slave1、2）authorized_keys文件 （6）master测试登录slave1、slave2（首次，需要“yes”确认连接）（7）同样操作，将slave1、2的id_dsa.pub传到master，追加authorized.keys 5、安装、配置JDK（1）mkdir -pv &#x2F;usr&#x2F;java （2）tar -zxvf jdk-8u171-linux-x64.tar.gz -C &#x2F;usr&#x2F;java&#x2F; （3）vi &#x2F;etc&#x2F;profile 填写以下内容： export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_171 export CLASSPATH&#x3D;#JAVA_HOME&#x2F;lib&#x2F; export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin export PATH JAVA_HOME CLASSPATH 生效环境变量，并查看jdk版本： source &#x2F;etc&#x2F;profile java -version 将master主机的jdk目录，分别拷贝slave1、slave2主机： scp -r root@master:&#x2F;usr&#x2F;java &#x2F;usr&#x2F; 将slave1、slave2配置jdk；并生效环境变量，查看jdk版本验证： export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_171 export CLASSPATH&#x3D;#JAVA_HOME&#x2F;lib&#x2F; export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin export PATH JAVA_HOME CLASSPATH 二、zookeeper1、修改主机名 与 IP地址映射设置（master、slave1、2都修改） vi &#x2F;etc&#x2F;hosts 192.168.88.151 node1 node1.root. 192.168.88.152 node2 node2.root 192.168.88.153 node3 node3.root 2、master节点执行操作：（1）创建zookeeper目录、解压解包；复制zoo.cfg： 或 egrep -v ‘(^#)’ zoo_sample.cfg | tee -a zoo.cfg （2）配置zoo.cfg vi zoo.cfg tickTime&#x3D;2000 initLimit&#x3D;10 syncLimit&#x3D;5 dataDir&#x3D;&#x2F;tmp&#x2F;zookeeper clientPort&#x3D;2181 dataDir&#x3D;&#x2F;usr&#x2F;zookeeper&#x2F;zookeeper-3.4.10&#x2F;zkdata dataLogDir&#x3D;&#x2F;usr&#x2F;zookeeper&#x2F;zookeeper-3.4.10&#x2F;zkdatalog server.1&#x3D;master:2888:3888 server.2&#x3D;slave1:2888:3888 server.3&#x3D;slave2:2888:3888 （3）在zookeeper目录中，创建zkdata、zkdatalog两个目录 （4）进入zkdata目录，创建文件myid： （5）将zookeeper目录分别slave1、slave2：scp -r &#x2F;usr&#x2F;zookeeper&#x2F; root@slave1:&#x2F;usr scp -r &#x2F;usr&#x2F;zookeeper&#x2F; root@slave2:&#x2F;usr （6）设置 myid配置的 dataDir 指定的目录下面，创建一个 myid 文件，里面内容为一个数字，用来标识当前主机，conf&#x2F;zoo.cfg 文件中配置的server.X 中 X 为什么数字，则 myid 文件中就输入这个数字。 （7）配置环境变量，并启动zookeeper（注：master、slave1、slave2）：export ZOOKEEPER_HOME&#x3D;&#x2F;usr&#x2F;zookeeper&#x2F;zookeeper-3.4.10 PATH&#x3D;$PATH:$ZOOKEEPER_HOME&#x2F;bin source &#x2F;etc&#x2F;profile （8）启动zookeeper集群 三、安装Hadoop1、创建&#x2F;usr&#x2F;hadoop目录、解压解包hadoop：（master节点操作） 将hadoop-2.7.3.tar.gz 解压解包放置&#x2F;usr&#x2F;hadoop目录 tar -zxvf hadoop-2.7.3.tar.gz -C &#x2F;usr&#x2F;hadoop&#x2F; 2、配置hadoop环境变量：（注：master、slave1、slave2均操作）vi &#x2F;etc&#x2F;profile export HADOOP_HOME&#x3D;&#x2F;usr&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F; export CLASSPATH&#x3D;$CLASSPATH:$HADOOP_HOME&#x2F;lib export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;bin source &#x2F;etc&#x2F;profile 3、编辑hadoop环境配置文件hadoop-env.sh路径：&#x2F;usr&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;etc&#x2F;hadoop 输入内容：export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_171 3、编辑core-site.xml（注：配置文件在当前路径下）填写以下配置文件： &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop/hadoop-2.7.3/hdfs/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131072&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.checkpoint.period&lt;/name&gt; &lt;value&gt;60&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.checkpoint.size&lt;/name&gt; &lt;value&gt;67108864&lt;/value&gt; &lt;/property&gt; 4、编辑yarn-site.xml：（注：配置文件路径在当前路径下）&lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:18040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:18030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;master:18088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;master:18025&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;master:18141&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; 5、编写slave文件与 master文件： 6、配置hdfs-site.xml&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/hadoop/hadoop-2.7.3/hdfs/name&lt;/value&gt; &lt;final&gt;true&lt;/final&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/hadoop/hadoop-2.7.3/hdfs/data&lt;/value&gt; &lt;final&gt;true&lt;/final&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;master:9001&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; 7、编辑mapred-site.xml将模板mapred-site.xml.template 复制为 mapred-site.xml cp mapred-site.xml.template mapred-site.xml 编写mapred-site.xml 填写以下内容： &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; 8、向slave1、slave2分发Hadoop目录：scp -r &#x2F;usr&#x2F;hadoop root@slave1:&#x2F;usr&#x2F; scp -r &#x2F;usr&#x2F;hadoop root@slave2:&#x2F;usr&#x2F; 9、master节点中格式化hadoop执行： hdfs namenode -format 访问master节点 master:50070 （注：50070 是hdfs的Web管理页面）","raw":"---\ntitle: Spark基础环境配置\ndate: 2024-06-03 12:56:35\ntags: 基础环境，JDK，Hadoop，Zookeeper\n---\n\n# 一、基础环境：\n\n## 1、主机名：\n\n| 序号 | 主机名 | IP Address     |\n| ---- | ------ | -------------- |\n| 01   | node1  | 192.168.88.151 |\n| 02   | node2  | 192.168.88.152 |\n| 03   | node3  | 192.168.88.153 |\n\n## 2、配置hosts：（注：三台服务器同时配置）\n\n![img](/2024/06/03/Spark1/clip_image002.jpg)\n\n测试：（每台服务器都测试）\n\n![img](/2024/06/03/Spark1/clip_image004.jpg)\n\n![img](/2024/06/03/Spark1/clip_image006.jpg)\n\n![img](/2024/06/03/Spark1/clip_image008.jpg)\n\n \n\n## 3、安装NTP：（master做NTP服务器，slave1、slave2同步master）\n\n（1）matser： yum -y install ntp \n\n![img](/2024/06/03/Spark1/clip_image010.jpg)\n\nsystemctl enable ntpd && systemctl start ntpd \n\n![img](/2024/06/03/Spark1/clip_image012.jpg)\n\n三台服务器需执行以上命令。\n\nServer:\n\n![img](/2024/06/03/Spark1/clip_image014.jpg)\n\nClient:\n\n![img](/2024/06/03/Spark1/clip_image016.jpg)\n\n![img](/2024/06/03/Spark1/clip_image018.jpg)\n\n检查：（master、slave1、slave2）\n\n![img](/2024/06/03/Spark1/clip_image020.jpg)\n\n![img](/2024/06/03/Spark1/clip_image022.jpg)\n\n![img](/2024/06/03/Spark1/clip_image024.jpg)\n\n \n\n## 4、配置SSH免密码\n\n### （1）所有节点分别生成私有密钥\n\nssh-keygen -t dsa -P '' -f /root/.ssh/id_dsa\n\n![img](/2024/06/03/Spark1/clip_image026.jpg)\n\n![img](/2024/06/03/Spark1/clip_image028.jpg)\n\n![img](/2024/06/03/Spark1/clip_image030.jpg)\n\n### （2）将公钥文件复制为authorized_keys文件\n\n![img](/2024/06/03/Spark1/clip_image032.jpg)\n\n### （3）mater主机连接自己，做SSH内环测试\n\n![img](/2024/06/03/Spark1/clip_image034.gif)\n\n### （4）slave1、slave2节点将master公钥文件复制本机（注：密码验证）\n\n![img](/2024/06/03/Spark1/clip_image036.jpg)\n\n![img](/2024/06/03/Spark1/clip_image038.jpg)\n\n### （5）将master节点公钥文件追加各个节点（slave1、2）authorized_keys文件\n\n![img](/2024/06/03/Spark1/clip_image040.jpg)\n\n![img](/2024/06/03/Spark1/clip_image042.jpg)\n\n### （6）master测试登录slave1、slave2（首次，需要“yes”确认连接）\n\n### （7）同样操作，将slave1、2的id_dsa.pub传到master，追加authorized.keys\n\n![img](/2024/06/03/Spark1/clip_image044.jpg)\n\n## 5、安装、配置JDK\n\n（1）mkdir -pv /usr/java \n\n（2）tar -zxvf jdk-8u171-linux-x64.tar.gz -C /usr/java/\n\n![img](/2024/06/03/Spark1/clip_image046.jpg)\n\n（3）vi /etc/profile\n\n填写以下内容：\n\nexport JAVA_HOME=/usr/java/jdk1.8.0_171\n\nexport CLASSPATH=#JAVA_HOME/lib/\n\nexport PATH=$PATH:$JAVA_HOME/bin\n\nexport PATH JAVA_HOME CLASSPATH \n\n![img](/2024/06/03/Spark1/clip_image048.jpg)\n\n生效环境变量，并查看jdk版本：\n\nsource /etc/profile \n\njava -version \n\n将master主机的jdk目录，分别拷贝slave1、slave2主机：\n\nscp -r root@master:/usr/java  /usr/\n\n将slave1、slave2配置jdk；并生效环境变量，查看jdk版本验证：\n\nexport JAVA_HOME=/usr/java/jdk1.8.0_171\n\nexport CLASSPATH=#JAVA_HOME/lib/\n\nexport PATH=$PATH:$JAVA_HOME/bin\n\nexport PATH JAVA_HOME CLASSPATH \n\n![img](/2024/06/03/Spark1/clip_image050.jpg)\n\n# 二、zookeeper\n\n## 1、修改主机名 与 IP地址映射设置（master、slave1、2都修改）\n\n| vi /etc/hosts  |       |             |\n| -------------- | ----- | ----------- |\n| 192.168.88.151 | node1 | node1.root. |\n| 192.168.88.152 | node2 | node2.root  |\n| 192.168.88.153 | node3 | node3.root  |\n\n![img](/2024/06/03/Spark1/clip_image052.jpg)\n\n## 2、master节点执行操作：\n\n### （1）创建zookeeper目录、解压解包；复制zoo.cfg：\n\n![img](/2024/06/03/Spark1/clip_image054.jpg)\n\n![img](/2024/06/03/Spark1/clip_image056.jpg)\n\n或 egrep -v '(^#)' zoo_sample.cfg | tee -a zoo.cfg\n\n### （2）配置zoo.cfg\n\n![img](/2024/06/03/Spark1/clip_image058.jpg)\n\nvi zoo.cfg \n\ntickTime=2000\n\ninitLimit=10\n\nsyncLimit=5\n\ndataDir=/tmp/zookeeper\n\nclientPort=2181\n\ndataDir=/usr/zookeeper/zookeeper-3.4.10/zkdata\n\ndataLogDir=/usr/zookeeper/zookeeper-3.4.10/zkdatalog\n\nserver.1=master:2888:3888\n\nserver.2=slave1:2888:3888\n\nserver.3=slave2:2888:3888\n\n![555](/2024/06/03/Spark1/clip_image060.gif)\n\n### （3）在zookeeper目录中，创建zkdata、zkdatalog两个目录\n\n![img](/2024/06/03/Spark1/clip_image062.jpg)\n\n### （4）进入zkdata目录，创建文件myid：\n\n![img](/2024/06/03/Spark1/clip_image064.jpg)\n\n### （5）将zookeeper目录分别slave1、slave2：\n\nscp -r /usr/zookeeper/ root@slave1:/usr\n\n![img](/2024/06/03/Spark1/clip_image066.jpg)\n\nscp -r /usr/zookeeper/ root@slave2:/usr\n\n![img](/2024/06/03/Spark1/clip_image068.jpg)\n\n### （6）设置 myid\n\n配置的 dataDir 指定的目录下面，创建一个 myid 文件，里面内容为一个数字，用来标识当前主机，conf/zoo.cfg 文件中配置的server.X 中 X 为什么数字，则 myid 文件中就输入这个数字。\n\n![img](/2024/06/03/Spark1/clip_image070.jpg)\n\n![img](/2024/06/03/Spark1/clip_image072.jpg)\n\n### （7）配置环境变量，并启动zookeeper（注：master、slave1、slave2）：\n\nexport ZOOKEEPER_HOME=/usr/zookeeper/zookeeper-3.4.10\n\nPATH=$PATH:$ZOOKEEPER_HOME/bin\n\n![img](/2024/06/03/Spark1/clip_image074.jpg)\n\nsource /etc/profile\n\n### （8）启动zookeeper集群\n\n![img](/2024/06/03/Spark1/clip_image076.jpg)\n\n# 三、安装Hadoop\n\n## 1、创建/usr/hadoop目录、解压解包hadoop：（master节点操作）\n\n![739a645a92f050b2f7621a0d2347516](/2024/06/03/Spark1/clip_image078.gif)\n\n将hadoop-2.7.3.tar.gz 解压解包放置/usr/hadoop目录\n\ntar -zxvf hadoop-2.7.3.tar.gz -C /usr/hadoop/\n\n## 2、配置hadoop环境变量：（注：master、slave1、slave2均操作）\n\nvi /etc/profile \n\nexport HADOOP_HOME=/usr/hadoop/hadoop-2.7.3/\n\nexport CLASSPATH=$CLASSPATH:$HADOOP_HOME/lib\n\nexport PATH=$PATH:$HADOOP_HOME/bin\n\nsource /etc/profile \n\n![edea1819d194e4225e67db1d3242aca](/2024/06/03/Spark1/clip_image080.gif)\n\n## 3、编辑hadoop环境配置文件hadoop-env.sh\n\n路径：/usr/hadoop/hadoop-2.7.3/etc/hadoop\n\n![d08312cfc2cba2d400f8a6d7ffffd7d](/2024/06/03/Spark1/clip_image082.gif)\n\n输入内容：export JAVA_HOME=/usr/java/jdk1.8.0_171\n\n## 3、编辑core-site.xml（注：配置文件在当前路径下）\n\n填写以下配置文件：\n\n    <property>\n        <name>fs.default.name</name>\n        <value>hdfs://master:9000</value>\n    </property>\n    <property>\n        <name>hadoop.tmp.dir</name>\n        <value>/usr/hadoop/hadoop-2.7.3/hdfs/tmp</value>\n        <description>A base for other temporary directories.</description>\n    </property>\n     <property>\n        <name>io.file.buffer.size</name>\n        <value>131072</value>\n    </property>\n    <property>\n        <name>fs.checkpoint.period</name>\n        <value>60</value>\n    </property>\n    <property>\n        <name>fs.checkpoint.size</name>\n        <value>67108864</value>\n    </property>\n\n![img](/2024/06/03/Spark1/clip_image084.gif)\n\n## 4、编辑yarn-site.xml：（注：配置文件路径在当前路径下）\n\n    <property>\n        <name>yarn.resourcemanager.address</name>\n        <value>master:18040</value>\n    </property>\n    <property>\n        <name>yarn.resourcemanager.scheduler.address</name>\n        <value>master:18030</value>\n    </property>\n    <property>\n        <name>yarn.resourcemanager.webapp.address</name>\n        <value>master:18088</value>\n    </property>\n    <property>\n        <name>yarn.resourcemanager.resource-tracker.address</name>\n        <value>master:18025</value>\n    </property>\n    <property>\n        <name>yarn.resourcemanager.admin.address</name>\n        <value>master:18141</value>\n    </property>\n    <property>\n        <name>yarn.nodemanager.aux-services</name>\n        <value>mapreduce_shuffle</value>\n    </property>\n    <property>  <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>\n        <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n    </property>\n\n![img](/2024/06/03/Spark1/clip_image086.gif)\n\n## 5、编写slave文件与 master文件：\n\n![img](/2024/06/03/Spark1/clip_image088.gif)\n\n## 6、配置hdfs-site.xml\n\n    <property>\n        <name>dfs.replication</name>\n        <value>2</value>\n    </property>\n     <property>\n        <name>dfs.namenode.name.dir</name>\n        <value>file:/usr/hadoop/hadoop-2.7.3/hdfs/name</value>\n        <final>true</final>\n    </property>\n    <property>\n        <name>dfs.datanode.data.dir</name>\n        <value>file:/usr/hadoop/hadoop-2.7.3/hdfs/data</value>\n        <final>true</final>\n    </property>\n    <property>\n        <name>dfs.namenode.secondary.http-address</name>\n        <value>master:9001</value>\n    </property>\n     <property>\n        <name>dfs.webhdfs.enabled</name>\n        <value>true</value>\n    </property>\n     <property>\n        <name>dfs.permissions</name>\n        <value>false</value>\n    </property>\n\n![img](/2024/06/03/Spark1/clip_image090.gif)\n\n## 7、编辑mapred-site.xml\n\n将模板mapred-site.xml.template 复制为 mapred-site.xml\n\n cp mapred-site.xml.template mapred-site.xml\n\n编写mapred-site.xml 填写以下内容：\n\n    <property>\n        <name>mapreduce.framework.name</name>\n        <value>yarn</value>\n    </property>\n![img](/2024/06/03/Spark1/clip_image092.gif)\n\n## 8、向slave1、slave2分发Hadoop目录：\n\nscp -r /usr/hadoop root@slave1:/usr/\n\nscp -r /usr/hadoop root@slave2:/usr/\n\n## 9、master节点中格式化hadoop\n\n执行： hdfs namenode -format\n\n![img](/2024/06/03/Spark1/clip_image094.gif)\n\n访问master节点  master:50070 （注：50070 是hdfs的Web管理页面）\n\n![img](/2024/06/03/Spark1/clip_image096.jpg)\n\n![img](/2024/06/03/Spark1/clip_image098.gif)","content":"<h1 id=\"一、基础环境：\"><a href=\"#一、基础环境：\" class=\"headerlink\" title=\"一、基础环境：\"></a>一、基础环境：</h1><h2 id=\"1、主机名：\"><a href=\"#1、主机名：\" class=\"headerlink\" title=\"1、主机名：\"></a>1、主机名：</h2><table>\n<thead>\n<tr>\n<th>序号</th>\n<th>主机名</th>\n<th>IP Address</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>01</td>\n<td>node1</td>\n<td>192.168.88.151</td>\n</tr>\n<tr>\n<td>02</td>\n<td>node2</td>\n<td>192.168.88.152</td>\n</tr>\n<tr>\n<td>03</td>\n<td>node3</td>\n<td>192.168.88.153</td>\n</tr>\n</tbody></table>\n<h2 id=\"2、配置hosts：（注：三台服务器同时配置）\"><a href=\"#2、配置hosts：（注：三台服务器同时配置）\" class=\"headerlink\" title=\"2、配置hosts：（注：三台服务器同时配置）\"></a>2、配置hosts：（注：三台服务器同时配置）</h2><p><img src=\"/2024/06/03/Spark1/clip_image002.jpg\" alt=\"img\"></p>\n<p>测试：（每台服务器都测试）</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image004.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image006.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image008.jpg\" alt=\"img\"></p>\n<h2 id=\"3、安装NTP：（master做NTP服务器，slave1、slave2同步master）\"><a href=\"#3、安装NTP：（master做NTP服务器，slave1、slave2同步master）\" class=\"headerlink\" title=\"3、安装NTP：（master做NTP服务器，slave1、slave2同步master）\"></a>3、安装NTP：（master做NTP服务器，slave1、slave2同步master）</h2><p>（1）matser： yum -y install ntp </p>\n<p><img src=\"/2024/06/03/Spark1/clip_image010.jpg\" alt=\"img\"></p>\n<p>systemctl enable ntpd &amp;&amp; systemctl start ntpd </p>\n<p><img src=\"/2024/06/03/Spark1/clip_image012.jpg\" alt=\"img\"></p>\n<p>三台服务器需执行以上命令。</p>\n<p>Server:</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image014.jpg\" alt=\"img\"></p>\n<p>Client:</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image016.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image018.jpg\" alt=\"img\"></p>\n<p>检查：（master、slave1、slave2）</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image020.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image022.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image024.jpg\" alt=\"img\"></p>\n<h2 id=\"4、配置SSH免密码\"><a href=\"#4、配置SSH免密码\" class=\"headerlink\" title=\"4、配置SSH免密码\"></a>4、配置SSH免密码</h2><h3 id=\"（1）所有节点分别生成私有密钥\"><a href=\"#（1）所有节点分别生成私有密钥\" class=\"headerlink\" title=\"（1）所有节点分别生成私有密钥\"></a>（1）所有节点分别生成私有密钥</h3><p>ssh-keygen -t dsa -P ‘’ -f &#x2F;root&#x2F;.ssh&#x2F;id_dsa</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image026.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image028.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image030.jpg\" alt=\"img\"></p>\n<h3 id=\"（2）将公钥文件复制为authorized-keys文件\"><a href=\"#（2）将公钥文件复制为authorized-keys文件\" class=\"headerlink\" title=\"（2）将公钥文件复制为authorized_keys文件\"></a>（2）将公钥文件复制为authorized_keys文件</h3><p><img src=\"/2024/06/03/Spark1/clip_image032.jpg\" alt=\"img\"></p>\n<h3 id=\"（3）mater主机连接自己，做SSH内环测试\"><a href=\"#（3）mater主机连接自己，做SSH内环测试\" class=\"headerlink\" title=\"（3）mater主机连接自己，做SSH内环测试\"></a>（3）mater主机连接自己，做SSH内环测试</h3><p><img src=\"/2024/06/03/Spark1/clip_image034.gif\" alt=\"img\"></p>\n<h3 id=\"（4）slave1、slave2节点将master公钥文件复制本机（注：密码验证）\"><a href=\"#（4）slave1、slave2节点将master公钥文件复制本机（注：密码验证）\" class=\"headerlink\" title=\"（4）slave1、slave2节点将master公钥文件复制本机（注：密码验证）\"></a>（4）slave1、slave2节点将master公钥文件复制本机（注：密码验证）</h3><p><img src=\"/2024/06/03/Spark1/clip_image036.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image038.jpg\" alt=\"img\"></p>\n<h3 id=\"（5）将master节点公钥文件追加各个节点（slave1、2）authorized-keys文件\"><a href=\"#（5）将master节点公钥文件追加各个节点（slave1、2）authorized-keys文件\" class=\"headerlink\" title=\"（5）将master节点公钥文件追加各个节点（slave1、2）authorized_keys文件\"></a>（5）将master节点公钥文件追加各个节点（slave1、2）authorized_keys文件</h3><p><img src=\"/2024/06/03/Spark1/clip_image040.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image042.jpg\" alt=\"img\"></p>\n<h3 id=\"（6）master测试登录slave1、slave2（首次，需要“yes”确认连接）\"><a href=\"#（6）master测试登录slave1、slave2（首次，需要“yes”确认连接）\" class=\"headerlink\" title=\"（6）master测试登录slave1、slave2（首次，需要“yes”确认连接）\"></a>（6）master测试登录slave1、slave2（首次，需要“yes”确认连接）</h3><h3 id=\"（7）同样操作，将slave1、2的id-dsa-pub传到master，追加authorized-keys\"><a href=\"#（7）同样操作，将slave1、2的id-dsa-pub传到master，追加authorized-keys\" class=\"headerlink\" title=\"（7）同样操作，将slave1、2的id_dsa.pub传到master，追加authorized.keys\"></a>（7）同样操作，将slave1、2的id_dsa.pub传到master，追加authorized.keys</h3><p><img src=\"/2024/06/03/Spark1/clip_image044.jpg\" alt=\"img\"></p>\n<h2 id=\"5、安装、配置JDK\"><a href=\"#5、安装、配置JDK\" class=\"headerlink\" title=\"5、安装、配置JDK\"></a>5、安装、配置JDK</h2><p>（1）mkdir -pv &#x2F;usr&#x2F;java </p>\n<p>（2）tar -zxvf jdk-8u171-linux-x64.tar.gz -C &#x2F;usr&#x2F;java&#x2F;</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image046.jpg\" alt=\"img\"></p>\n<p>（3）vi &#x2F;etc&#x2F;profile</p>\n<p>填写以下内容：</p>\n<p>export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_171</p>\n<p>export CLASSPATH&#x3D;#JAVA_HOME&#x2F;lib&#x2F;</p>\n<p>export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin</p>\n<p>export PATH JAVA_HOME CLASSPATH </p>\n<p><img src=\"/2024/06/03/Spark1/clip_image048.jpg\" alt=\"img\"></p>\n<p>生效环境变量，并查看jdk版本：</p>\n<p>source &#x2F;etc&#x2F;profile </p>\n<p>java -version </p>\n<p>将master主机的jdk目录，分别拷贝slave1、slave2主机：</p>\n<p>scp -r root@master:&#x2F;usr&#x2F;java  &#x2F;usr&#x2F;</p>\n<p>将slave1、slave2配置jdk；并生效环境变量，查看jdk版本验证：</p>\n<p>export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_171</p>\n<p>export CLASSPATH&#x3D;#JAVA_HOME&#x2F;lib&#x2F;</p>\n<p>export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin</p>\n<p>export PATH JAVA_HOME CLASSPATH </p>\n<p><img src=\"/2024/06/03/Spark1/clip_image050.jpg\" alt=\"img\"></p>\n<h1 id=\"二、zookeeper\"><a href=\"#二、zookeeper\" class=\"headerlink\" title=\"二、zookeeper\"></a>二、zookeeper</h1><h2 id=\"1、修改主机名-与-IP地址映射设置（master、slave1、2都修改）\"><a href=\"#1、修改主机名-与-IP地址映射设置（master、slave1、2都修改）\" class=\"headerlink\" title=\"1、修改主机名 与 IP地址映射设置（master、slave1、2都修改）\"></a>1、修改主机名 与 IP地址映射设置（master、slave1、2都修改）</h2><table>\n<thead>\n<tr>\n<th>vi &#x2F;etc&#x2F;hosts</th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>192.168.88.151</td>\n<td>node1</td>\n<td>node1.root.</td>\n</tr>\n<tr>\n<td>192.168.88.152</td>\n<td>node2</td>\n<td>node2.root</td>\n</tr>\n<tr>\n<td>192.168.88.153</td>\n<td>node3</td>\n<td>node3.root</td>\n</tr>\n</tbody></table>\n<p><img src=\"/2024/06/03/Spark1/clip_image052.jpg\" alt=\"img\"></p>\n<h2 id=\"2、master节点执行操作：\"><a href=\"#2、master节点执行操作：\" class=\"headerlink\" title=\"2、master节点执行操作：\"></a>2、master节点执行操作：</h2><h3 id=\"（1）创建zookeeper目录、解压解包；复制zoo-cfg：\"><a href=\"#（1）创建zookeeper目录、解压解包；复制zoo-cfg：\" class=\"headerlink\" title=\"（1）创建zookeeper目录、解压解包；复制zoo.cfg：\"></a>（1）创建zookeeper目录、解压解包；复制zoo.cfg：</h3><p><img src=\"/2024/06/03/Spark1/clip_image054.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image056.jpg\" alt=\"img\"></p>\n<p>或 egrep -v ‘(^#)’ zoo_sample.cfg | tee -a zoo.cfg</p>\n<h3 id=\"（2）配置zoo-cfg\"><a href=\"#（2）配置zoo-cfg\" class=\"headerlink\" title=\"（2）配置zoo.cfg\"></a>（2）配置zoo.cfg</h3><p><img src=\"/2024/06/03/Spark1/clip_image058.jpg\" alt=\"img\"></p>\n<p>vi zoo.cfg </p>\n<p>tickTime&#x3D;2000</p>\n<p>initLimit&#x3D;10</p>\n<p>syncLimit&#x3D;5</p>\n<p>dataDir&#x3D;&#x2F;tmp&#x2F;zookeeper</p>\n<p>clientPort&#x3D;2181</p>\n<p>dataDir&#x3D;&#x2F;usr&#x2F;zookeeper&#x2F;zookeeper-3.4.10&#x2F;zkdata</p>\n<p>dataLogDir&#x3D;&#x2F;usr&#x2F;zookeeper&#x2F;zookeeper-3.4.10&#x2F;zkdatalog</p>\n<p>server.1&#x3D;master:2888:3888</p>\n<p>server.2&#x3D;slave1:2888:3888</p>\n<p>server.3&#x3D;slave2:2888:3888</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image060.gif\" alt=\"555\"></p>\n<h3 id=\"（3）在zookeeper目录中，创建zkdata、zkdatalog两个目录\"><a href=\"#（3）在zookeeper目录中，创建zkdata、zkdatalog两个目录\" class=\"headerlink\" title=\"（3）在zookeeper目录中，创建zkdata、zkdatalog两个目录\"></a>（3）在zookeeper目录中，创建zkdata、zkdatalog两个目录</h3><p><img src=\"/2024/06/03/Spark1/clip_image062.jpg\" alt=\"img\"></p>\n<h3 id=\"（4）进入zkdata目录，创建文件myid：\"><a href=\"#（4）进入zkdata目录，创建文件myid：\" class=\"headerlink\" title=\"（4）进入zkdata目录，创建文件myid：\"></a>（4）进入zkdata目录，创建文件myid：</h3><p><img src=\"/2024/06/03/Spark1/clip_image064.jpg\" alt=\"img\"></p>\n<h3 id=\"（5）将zookeeper目录分别slave1、slave2：\"><a href=\"#（5）将zookeeper目录分别slave1、slave2：\" class=\"headerlink\" title=\"（5）将zookeeper目录分别slave1、slave2：\"></a>（5）将zookeeper目录分别slave1、slave2：</h3><p>scp -r &#x2F;usr&#x2F;zookeeper&#x2F; root@slave1:&#x2F;usr</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image066.jpg\" alt=\"img\"></p>\n<p>scp -r &#x2F;usr&#x2F;zookeeper&#x2F; root@slave2:&#x2F;usr</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image068.jpg\" alt=\"img\"></p>\n<h3 id=\"（6）设置-myid\"><a href=\"#（6）设置-myid\" class=\"headerlink\" title=\"（6）设置 myid\"></a>（6）设置 myid</h3><p>配置的 dataDir 指定的目录下面，创建一个 myid 文件，里面内容为一个数字，用来标识当前主机，conf&#x2F;zoo.cfg 文件中配置的server.X 中 X 为什么数字，则 myid 文件中就输入这个数字。</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image070.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image072.jpg\" alt=\"img\"></p>\n<h3 id=\"（7）配置环境变量，并启动zookeeper（注：master、slave1、slave2）：\"><a href=\"#（7）配置环境变量，并启动zookeeper（注：master、slave1、slave2）：\" class=\"headerlink\" title=\"（7）配置环境变量，并启动zookeeper（注：master、slave1、slave2）：\"></a>（7）配置环境变量，并启动zookeeper（注：master、slave1、slave2）：</h3><p>export ZOOKEEPER_HOME&#x3D;&#x2F;usr&#x2F;zookeeper&#x2F;zookeeper-3.4.10</p>\n<p>PATH&#x3D;$PATH:$ZOOKEEPER_HOME&#x2F;bin</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image074.jpg\" alt=\"img\"></p>\n<p>source &#x2F;etc&#x2F;profile</p>\n<h3 id=\"（8）启动zookeeper集群\"><a href=\"#（8）启动zookeeper集群\" class=\"headerlink\" title=\"（8）启动zookeeper集群\"></a>（8）启动zookeeper集群</h3><p><img src=\"/2024/06/03/Spark1/clip_image076.jpg\" alt=\"img\"></p>\n<h1 id=\"三、安装Hadoop\"><a href=\"#三、安装Hadoop\" class=\"headerlink\" title=\"三、安装Hadoop\"></a>三、安装Hadoop</h1><h2 id=\"1、创建-usr-hadoop目录、解压解包hadoop：（master节点操作）\"><a href=\"#1、创建-usr-hadoop目录、解压解包hadoop：（master节点操作）\" class=\"headerlink\" title=\"1、创建&#x2F;usr&#x2F;hadoop目录、解压解包hadoop：（master节点操作）\"></a>1、创建&#x2F;usr&#x2F;hadoop目录、解压解包hadoop：（master节点操作）</h2><p><img src=\"/2024/06/03/Spark1/clip_image078.gif\" alt=\"739a645a92f050b2f7621a0d2347516\"></p>\n<p>将hadoop-2.7.3.tar.gz 解压解包放置&#x2F;usr&#x2F;hadoop目录</p>\n<p>tar -zxvf hadoop-2.7.3.tar.gz -C &#x2F;usr&#x2F;hadoop&#x2F;</p>\n<h2 id=\"2、配置hadoop环境变量：（注：master、slave1、slave2均操作）\"><a href=\"#2、配置hadoop环境变量：（注：master、slave1、slave2均操作）\" class=\"headerlink\" title=\"2、配置hadoop环境变量：（注：master、slave1、slave2均操作）\"></a>2、配置hadoop环境变量：（注：master、slave1、slave2均操作）</h2><p>vi &#x2F;etc&#x2F;profile </p>\n<p>export HADOOP_HOME&#x3D;&#x2F;usr&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;</p>\n<p>export CLASSPATH&#x3D;$CLASSPATH:$HADOOP_HOME&#x2F;lib</p>\n<p>export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;bin</p>\n<p>source &#x2F;etc&#x2F;profile </p>\n<p><img src=\"/2024/06/03/Spark1/clip_image080.gif\" alt=\"edea1819d194e4225e67db1d3242aca\"></p>\n<h2 id=\"3、编辑hadoop环境配置文件hadoop-env-sh\"><a href=\"#3、编辑hadoop环境配置文件hadoop-env-sh\" class=\"headerlink\" title=\"3、编辑hadoop环境配置文件hadoop-env.sh\"></a>3、编辑hadoop环境配置文件hadoop-env.sh</h2><p>路径：&#x2F;usr&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;etc&#x2F;hadoop</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image082.gif\" alt=\"d08312cfc2cba2d400f8a6d7ffffd7d\"></p>\n<p>输入内容：export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_171</p>\n<h2 id=\"3、编辑core-site-xml（注：配置文件在当前路径下）\"><a href=\"#3、编辑core-site-xml（注：配置文件在当前路径下）\" class=\"headerlink\" title=\"3、编辑core-site.xml（注：配置文件在当前路径下）\"></a>3、编辑core-site.xml（注：配置文件在当前路径下）</h2><p>填写以下配置文件：</p>\n<pre><code>&lt;property&gt;\n    &lt;name&gt;fs.default.name&lt;/name&gt;\n    &lt;value&gt;hdfs://master:9000&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n    &lt;value&gt;/usr/hadoop/hadoop-2.7.3/hdfs/tmp&lt;/value&gt;\n    &lt;description&gt;A base for other temporary directories.&lt;/description&gt;\n&lt;/property&gt;\n &lt;property&gt;\n    &lt;name&gt;io.file.buffer.size&lt;/name&gt;\n    &lt;value&gt;131072&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;fs.checkpoint.period&lt;/name&gt;\n    &lt;value&gt;60&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;fs.checkpoint.size&lt;/name&gt;\n    &lt;value&gt;67108864&lt;/value&gt;\n&lt;/property&gt;\n</code></pre>\n<p><img src=\"/2024/06/03/Spark1/clip_image084.gif\" alt=\"img\"></p>\n<h2 id=\"4、编辑yarn-site-xml：（注：配置文件路径在当前路径下）\"><a href=\"#4、编辑yarn-site-xml：（注：配置文件路径在当前路径下）\" class=\"headerlink\" title=\"4、编辑yarn-site.xml：（注：配置文件路径在当前路径下）\"></a>4、编辑yarn-site.xml：（注：配置文件路径在当前路径下）</h2><pre><code>&lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;\n    &lt;value&gt;master:18040&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;\n    &lt;value&gt;master:18030&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;\n    &lt;value&gt;master:18088&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;\n    &lt;value&gt;master:18025&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;\n    &lt;value&gt;master:18141&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;  &lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt;\n    &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;\n&lt;/property&gt;\n</code></pre>\n<p><img src=\"/2024/06/03/Spark1/clip_image086.gif\" alt=\"img\"></p>\n<h2 id=\"5、编写slave文件与-master文件：\"><a href=\"#5、编写slave文件与-master文件：\" class=\"headerlink\" title=\"5、编写slave文件与 master文件：\"></a>5、编写slave文件与 master文件：</h2><p><img src=\"/2024/06/03/Spark1/clip_image088.gif\" alt=\"img\"></p>\n<h2 id=\"6、配置hdfs-site-xml\"><a href=\"#6、配置hdfs-site-xml\" class=\"headerlink\" title=\"6、配置hdfs-site.xml\"></a>6、配置hdfs-site.xml</h2><pre><code>&lt;property&gt;\n    &lt;name&gt;dfs.replication&lt;/name&gt;\n    &lt;value&gt;2&lt;/value&gt;\n&lt;/property&gt;\n &lt;property&gt;\n    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n    &lt;value&gt;file:/usr/hadoop/hadoop-2.7.3/hdfs/name&lt;/value&gt;\n    &lt;final&gt;true&lt;/final&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n    &lt;value&gt;file:/usr/hadoop/hadoop-2.7.3/hdfs/data&lt;/value&gt;\n    &lt;final&gt;true&lt;/final&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;\n    &lt;value&gt;master:9001&lt;/value&gt;\n&lt;/property&gt;\n &lt;property&gt;\n    &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n&lt;/property&gt;\n &lt;property&gt;\n    &lt;name&gt;dfs.permissions&lt;/name&gt;\n    &lt;value&gt;false&lt;/value&gt;\n&lt;/property&gt;\n</code></pre>\n<p><img src=\"/2024/06/03/Spark1/clip_image090.gif\" alt=\"img\"></p>\n<h2 id=\"7、编辑mapred-site-xml\"><a href=\"#7、编辑mapred-site-xml\" class=\"headerlink\" title=\"7、编辑mapred-site.xml\"></a>7、编辑mapred-site.xml</h2><p>将模板mapred-site.xml.template 复制为 mapred-site.xml</p>\n<p> cp mapred-site.xml.template mapred-site.xml</p>\n<p>编写mapred-site.xml 填写以下内容：</p>\n<pre><code>&lt;property&gt;\n    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n    &lt;value&gt;yarn&lt;/value&gt;\n&lt;/property&gt;\n</code></pre>\n<p><img src=\"/2024/06/03/Spark1/clip_image092.gif\" alt=\"img\"></p>\n<h2 id=\"8、向slave1、slave2分发Hadoop目录：\"><a href=\"#8、向slave1、slave2分发Hadoop目录：\" class=\"headerlink\" title=\"8、向slave1、slave2分发Hadoop目录：\"></a>8、向slave1、slave2分发Hadoop目录：</h2><p>scp -r &#x2F;usr&#x2F;hadoop root@slave1:&#x2F;usr&#x2F;</p>\n<p>scp -r &#x2F;usr&#x2F;hadoop root@slave2:&#x2F;usr&#x2F;</p>\n<h2 id=\"9、master节点中格式化hadoop\"><a href=\"#9、master节点中格式化hadoop\" class=\"headerlink\" title=\"9、master节点中格式化hadoop\"></a>9、master节点中格式化hadoop</h2><p>执行： hdfs namenode -format</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image094.gif\" alt=\"img\"></p>\n<p>访问master节点  master:50070 （注：50070 是hdfs的Web管理页面）</p>\n<p><img src=\"/2024/06/03/Spark1/clip_image096.jpg\" alt=\"img\"></p>\n<p><img src=\"/2024/06/03/Spark1/clip_image098.gif\" alt=\"img\"></p>\n","slug":"Spark1","updated":"2024-06-05T02:14:12.000Z","comments":true,"permalink":"http://example.com/2024/06/03/Spark1/","tags":[{"name":"基础环境，JDK，Hadoop，Zookeeper","slug":"基础环境，JDK，Hadoop，Zookeeper","permalink":"http://example.com/tags/%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%EF%BC%8CJDK%EF%BC%8CHadoop%EF%BC%8CZookeeper/"}]}],"categories":[],"tags":[{"name":"Spark(HA)，Spark(Yarn)","slug":"Spark-HA-，Spark-Yarn","permalink":"http://example.com/tags/Spark-HA-%EF%BC%8CSpark-Yarn/"},{"name":"Spark(local)，Spark(stand-alone)","slug":"Spark-local-，Spark-stand-alone","permalink":"http://example.com/tags/Spark-local-%EF%BC%8CSpark-stand-alone/"},{"name":"基础环境，JDK，Hadoop，Zookeeper","slug":"基础环境，JDK，Hadoop，Zookeeper","permalink":"http://example.com/tags/%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%EF%BC%8CJDK%EF%BC%8CHadoop%EF%BC%8CZookeeper/"}]}